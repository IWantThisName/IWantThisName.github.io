<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[mongodb学习]]></title>
      <url>%2F2016%2F11%2F01%2Fmongodb%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[Mongodb目录建立 安装mongodb进入mongodb/bin目录Shift加右键进入命令行窗口mongod –dbpath=F:\develop\mongodb\dbrepository–logpath=F:\develop\mongodb\log.txt –install执行以上命令,mongodb数据库就安装成功了然后执行 net start MongoDB即开启mongodb数据库服务 卸载mongodb服务net stop MongoDb关闭mongodb数据库服务后执行以下命令mongod –dbpath=F:\develop\mongodb\dbrepository–logpath=F:\develop\mongodb\log.txt –remove使用客户端连接数据库直接在命令行输入 mongo.exe就可 Mongo常用操作 查询当前数据库名称db.getName() 创建数据库Use 数据库名称 查看数据库状态db.stats() 简单运算 查看数据库相关帮助信息db.help() 写入数据 普通数据的添加Json格式 Bson格式，类json格式db.goods.insert({name:”huawei”,price:1000,weight:135,number:35}) 多维数据的添加db.goods.insert({name:”huawei”,price:1000,weight:135,number:35,area:{province:anhui,city:hefei}}) 数组信息的添加db.goods.insert({name:”huawei”,price:1000,weight:135,number:35,area:{province:anhui,city:hefei},color:[“blank”,”white”,”red”]}) 数据查询 笼统方式查询1.1 db.数据表.find() //查询数据表的全部数据1.2 db.数据表.findOne() //查询数据表中的第一条数据 条件限制查询2.1 db.数据表.find(条件) //条件也用键值对db.goods.find({name:”huawei”}) //相当于 select * from goods where name = “huawei”2.2 db.数据表.findOne(条件) //返回满足结果里的第一条消息db.goods.findOne({name:”huawei”})值得一提的是,mongodb中的_id的值是mongodb自身算法算出来的,全球唯一,也可以显示去指定_id的值,db.goods.insert({_id:2,….}),但是不建议这么做 范围条件查询关键字: $lt,$gt,$lte,$gte相当于mysql中的 &lt; &gt; &lt;= &gt;=db.goods.find({price:{‘$gte’:1000}}) //查询价格大于等于1000的商品注意:$gte必须用引号括起来,单双引号都行 设置多个查询条件db.数据表.find({条件,条件,条件}) 相当于sql的anddb.goods.find({price:{“$gte”:1000},weight:{”$lte”:135}})//查询价格大于等于1000并且重量小于等于135的商品db.goods.find({price:{“$gte”:1000},weight:135})查询价格大于等于1000并且重量为135的商品 多维字段的查询db.数据表.find({“key.name”:值})多维字段查询和普通字段写法相似,都是写条件,不过区别是条件的键是key.name多维形式的 数组条件查询db.goods.find({color:”white”}) //只要color数组中有white这个值就行db.goods.find({color:{“$all”:[“black”,”white”]}})$all代表全部满足 所以当color数组中同时有black和white就满足这个查询条件 限制查询条件我们刚才的查询，是显示的所有的信息字段，但是呢，实际情况操作中，我们不一定全部都用到，那么可以就需要做一个字段输出查询的一个限制。如果全部取出来的话，对于内存和带宽都一定影响，我们按需去操作就可以了。db.表.find({条件},{字段：1/0,字段：1/0}1: 查询此字段0: 排除此字段规则：就是要输出就全部输出，要不输出就全部不输出。_id 除外，可以随意设置0,1,并且_id默认是输出的db.goods.find({price:{“$gte”:1000},{name:1,_id:0}}) //这个可以正常查询db.goods.find({price:{“$gte”:1000},{name:0,price:1}}) //这个会报错,因为要么就全写需要输出的,要么就全写不需要输出的要是0都是0，要是1都是1 $or查询，多个条件，满足其一即可db.goods.find({“$or”:[{price:{“$gt”:1000}},{weight:135}]}) 修改数据db.表.update({条件},{‘$set’:{字段：值,字段:值……}})db.表.update({条件},{字段：值,字段:值……})有$set的修改：只修改设置的字段，其他字段不变化没有$set的修改：只修改设置的字段，没有修改的字段就删除了(除了_id字段) 数据表原来没有的字段直接添加为新字段 删除数据1)删除记录 db.表.remove(条件)2)删除字段 db.表.update({条件},{‘$unset’:{字段:1/字段:0}}) 0和1没有区别]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python学习2]]></title>
      <url>%2F2016%2F10%2F25%2Fpython%E5%AD%A6%E4%B9%A02%2F</url>
      <content type="text"><![CDATA[python中的io流 打开文件在python,使用open函数,可以打开一个已经存在的文件,或者创建一个新文件open(文件名,访问模式)用法:f = open(‘test.txt’,’w’)说明:以可写方式打开test.txt文件,f用于代表文件对象访问模式主要有以下几种:r 以只读方式打开文件.文件的指针将会放在文件的开头.这是默认模式w 打开一个文件只用于写入.如果该文件已存在则将其覆盖.如果该文件不存在,创建新文件a 打开一个文件用于追加.如果该文件已存在,文件指针将会放在文件的结尾.也就是说,新的内容将会写入到已有内容之后.如果该文件不存在,创建新文件进行写入.rb 以二进制格式打开一个文件用于只读.文件指针将会放在文件的开头.这是默认模式wb 以二进制格式打开一个文件只用于写入.如果该文件已存在则将其覆盖.如果该文件不存在,创建新文件ab 以二进制格式打开一个文件用于追加.如果该文件已存在,文件指针将会放在文件的末尾.也就是说,新的内容将会被写入到已有内容之后,如果该文件不存在,创建新文件进行写入r+ 打开一个文件用于读写.文件指针将会放在文件的开头.w+ 打开一个文件用于读写.如果该文件已存在则将其覆盖.如果该文件不存在,创建新文件a+ 打开一个文件用于读写,如果该文件存在,文件指针将会放在文件的结尾.文件打开时会是追加模式.如果该文件不存在,创建新文件用于读写.rb+ 以二进制格式打开一个文件用于读写.文件指针将会放在文件的开头.wb+ 以二进制格式打开一个文件用于读写.如果该文件已存在则将其覆盖.如果该文件不存在,创建新文件..ab+ 以二进制格式打开一个文件用于追加.如果该文件已存在,文件指针将会放在文件的结尾.如果该文件不存在,创建新文件用于读写 关闭文件close()用法 f.close() 文件的读写之写数据write() 可以向文件写入数据用法:f = open(‘test.txt’,’w’)f.write(‘hello world,i am python’)f.close()注意:如果文件不存在那么创建,如果存在那么就先清空,然后写入数据 文件的读写之读数据read(num) 可以从文件中读取数据,num表示要从文件中读取的数据的长度(单位是字节),如果没有传入num,那么就表示读取文件中所有的数据用法:f = open(‘text.txt’,’r’)content = f.read(5) #读取五个字节数据print(content)content = f.read() #不指定num,代表读取全部数据print(content)f.close()注意:r如果open是打开一个文件用于读数据,那么可以不用写打开的模式,即只写open(‘test.txt’) 如果使用read(num)方法多次,那么后面读取的数据是从上次读完后的位置开始的 读数据之readlines就像read没有参数时一样,readlines可以按照行的方式把整个文件中的内容进行一次性读取,并且返回的是一个列表,其中每一行的数据为一个元素用法:f = open(‘text.txt’,’r’)content = f.readlines() #content接收的是一个列表,列表中的每一个元素都是文件中的一行内容for i in content: print(i) 读数据之readline相较于readlines()是一次读取整个文件,将文件中的每一行都当成列表中的元素,然后返回列 表,,readline()是每调用一次,就读取一行数据,返回的是一个字符串,当多次使用时,后面读取的数据是从上次读完后的位置开始的用法:f = open(‘text.txt’,’r’)content = f.readline() #第一次调用,读取文件的第一行数据print(content)content = f.readline() #第二次调用,接着上次读完后的位置读取,读取文件的第二行数据print(content) 文件操作 获取当前读写的位置在读写文件的过程中,如果想知道当前的位置,可以使用tell()来获取 定位到某个位置如果在读写文件的过程中,需要从另外一个位置进行操作的话,可以使用seek(offset,from)offset:偏移量from: 方向 0:表示文件开头 1:表示当前位置 2:表示文件末尾从文件开头,偏移5个字节f = open(“test.txt”,”r”)f.seek(5,0)离文件末尾,3个字节f = open(“test.txt”,”r”)f.seek(-3,2) 文件重命名,删除有些时候,需要对文件进行重命名,删除等一些操作,python的os模块中都有这些功能 文件重命名os模块中的rename()可以完成对文件的重命名操作rename(需要修改的文件名,新的文件名)import os #导入os模块os.rename(“test.txt”,”demo.txt”) #将test.txt名字改为demo.txt 删除文件os模块中的remove()可以完成对文件的删除操作remove(待删除的文件名)import osos.remove(“test.txt”) #将test.txt文件删除 文件夹的相关操作os模块也可以用来操作文件夹1.创建文件夹import osos.mkdir(“张三”) #创建一个名称为张三的文件夹 获取当前目录import osos.getcwd() #获取当前的工作目录 改变默认目录import osos.chdir(“../“) #将当前工作目录改为上一级 获取目录列表import osos.listdir(“./“) #获取当前目录下的文件列表 删除文件夹import osos.rmdir(“张三”) #将名字为张三的文件夹删除 python中的类python中的类的概念和其他面向对象语言一样python中类的定义class 类名: 方法列表 创建对象格式对象名 = 类名() 对象的使用使用对象.一个不存在的属性,相当于给该对象添加属性 python中的init方法相当于java中的构造器,可以在创建对象时对对象进行数据的初始化操作 注意: init方法,在创建一个对象时默认被调用,不需要手动调用 init(self)中,默认有1个参数名字为self,如果在创建对象时传递了2个实参,那么 init(self)中除了 self作为第一个形参外还需要2个形参,例如init (self,x,y) init_(self)中的self参数,不需要开发者传递,pythono解释器会自己进行传递 魔法方法id()可以获取对象的地址值 #coding #面向对象的一些操作 class Car: def __init__(self,color,price): self.color = color self.color = price def run(): print(&quot;车在奔跑&quot;) def mingdi(): print(&quot;车在鸣笛...嘟嘟..&quot;) audi = Car(&quot;红色&quot;,&quot;50万&quot;) &gt;&gt;&gt; print(audi) &lt;__main__.Car object at 0x02F4B870&gt; (直接打印对象显示的是一串对象的信息) &gt;&gt;&gt; print(id(audi)) 49592432 (id方法获取对象的地址) str()方法相当于java中对象的toString()方法,在类中定义了这个方法,将会在打印对象时打印str方法中定义的内容在Car类加上str方法 def __str__(self): msg = &quot;车颜色是&quot;+self.color+&quot;,车价格是&quot;+self.price return msg 这时再创建对象,再打印对象,显示的就是str中定义的内容 audi = Car(&quot;红色&quot;,&quot;50万&quot;) &gt;&gt;&gt; print(audi) 车颜色是红色,车价格是50万 总结:在python中方法名如果是xxxx()的,那么就有特殊的功能,因此叫做”魔法”方法当使用能够print输出对象的时候,只要自己定义了str(self)方法,那么就会打印从在这个方法中return的数据 python的self相当于java中的this关键字 123456比如 self.color 可以被直接访问,self.__color 不可以被直接访问,方法同理 ```__del__() 方法 类似java对象中的finalize方法,当对象被清理时调用该方法 del 对象名 即是清理对象 不过python对于对象的处理和java不同当有1个变量保存了对象的引用时,此对象的引用计数就会加1当使用del删除变量指向的对象时,如果对象的引用技术不为1,比如3,那么此时只会让这个引用计数减1,即变为2,当再次调用del时,变为1,如果再调用1次del,此时会真的把对象进行删除 python中的继承python中的继承概念和java中的相同用法:子类在继承的时候,在定义类时,小括号()中为父类的名字 父类的属性,方法,会被继承给子类 注意点:私有的属性,不能通过对象直接访问,但是可以通过方法访问 私有的方法,不能通过对象直接访问 私有的属性,方法,不会被子类继承,也不能被访问 一般情况行啊,私有的属性,方法都是不对外公布的,往往用来做内部的事情,起到安全的作用 python是支持多继承的用法就是在定义类时,在类后面的括号里写上继承的类名,多个之间用逗号隔开class A() class B() class C(A,B)类C同时继承了类A和类B 类A和类B中的非私有方法都会被类C继承 当支持多继承时,就会出现一个现象,当继承的两个类中有相同的方法,这个类调用这个方法会产生什么效果可以通过类名.mro 查看对象搜索方法时的先后顺序(试了一下,貌似跟括号里写继承类的继承顺序有关) python中也有方法重写的概念,在子类中写跟父类同名的方法,可以覆盖掉父类的方法实现 python调用父类的方法是通过super()函数,super().方法名调用,跟java的不同就是多两个括号 python中的类属性和实例属性类属性就是直接在方法外定义的属性,实例属性,通过self.变量名定义的就是实例属性类属性和java中的静态变量相仿,实例属性和java中的实例变量相仿 修改类属性的话,必须通过类名.来调用修改,用对象名.调用的话,会在对象中新增一个同名的实例属性,之后用该对象引用时,都只会显示该实例属性的值,屏蔽掉了类属性,除非删除这个实例属性 del 对象名.属性 python中的类方法和静态方法类方法的定义,在方法名上加上注解@classmethod 则这个方法就变成了类方法,且该方法的参数得改成cls,代表该类的引用,而不是self对象的引用 静态方法的定义,在方法名上加上注解@staticmethod 则这个方法就变成了静态方法,静态方法不需要传任何参数,所以在静态方法中操作属性,只能通过类名.调用类属性 python中的异常python中报错 可以通过 try: xxx except 错误名: 解决方式 结构来抓取异常,进行相应操作 这里介绍python中的一个关键字 pass 使用pass代表实现了相应的实现,但是啥也没做 在接收错误名的后面,可以加上一个参数,errorMsg,用于接收具体的错误信息 try: xxxx except error,errorMsg: print(errorMsg) 捕获多个异常 ,可以使用元组的方式 try: xxxx except (error1,error2),errorMsg: print(errorMsg) python中 也可以在后面加上finally分支,用来进行一些必须要进行的操作,比如关闭链接 try: xxxx except error1,errorMsg: print(errorMsg) finally: 释放资源的操作 在抓取异常中还可以加入else分支,当没有抓取到异常时执行 try: xxxx except error,errorMsg: print(errorMsg) else: print(&quot;没有抓取到异常&quot;) finally: 释放资源操作 python中可以自定义异常,需要继承Error或者Exception抛异常,python使用raise关键字抛异常,类似于java的throw]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python学习]]></title>
      <url>%2F2016%2F10%2F22%2Fpython%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[python注释 单行注释以#开头,#右边的都是注释内容#打印hello worldprint(“hello world”) 多行注释使用三个单引号括起来的内容就是多行注释‘’’ 打印hello world‘’’print(“hello world”) python对中文的支持如果在文件中使用了中文,直接运行的话会报错,这是可以在程序上方加上一行coding=utf-8或者coding=gbk,具体编码格式怎么写根据你的文件编码确定 python变量以及类型python中定义变量方式为: 变量名 = 值 不需要指定具体的数据类型 但是python中还是有数据类型的,分为以下几种Numbers(数字) Boolean布尔类型 String字符串 List列表 Tuple元组 Dictionary字典Numbers具体还分为int 有符号整型 long 长整型(也可以代表八进制和十六禁止) float 浮点类型 complex 复数Boolean具体分为True 和 False 那么该怎么知道一个变量具体的数据类型呢在python中,只要定义了一个变量,而且它有数据,那么它的类型就已经确定了,不需要去主动说明具体类型,系统会自动辨别可以使用type 变量的名字,来查看变量的类型 python标识符python中的标识符和其他语言要求的规则一样,有字母数字下划线组成且数字不能开头,并且区分大小写 python的关键字大致上和其他语言差不多可以通过import keywordkeyword.kwlist查看当前python版本里的关键字 python的格式化输出和c语言很像,可以在字符串使用%数据类型进行格式化输出,因为python中的+不像java中可以充当连接符.当其他数据类型加到字符串中,可以使用格式化符进行格式化输出age = 18name = “xiaohua”print(“我的姓名是%s,年龄是%d”%(name,age)) 常用的格式符号%c 字符%s 通过str()字符串转换来格式化%i 有符号十进制整数%d 有符号十进制整数%u 无符号十进制整数%o 八进制整数%x 十六进制整数(小写字母)%X 十六进制整数(大写字母)%e 索引符号(小写 ‘e’)%E 索引符号(大写 ‘e’)%f 浮点实数%g %f和%e的简写%G %f和%E的简写 换行输出 \nprint(“123456—–”) #会在一行显示print(“123456\n—–”) #\n后面的内容会在下一行显示 获取键盘输入python2中获取键盘输入的是raw_input函数,用法如下:password = raw_input(“请输入密码:”)print ‘您刚刚输入的密码是:’,password 还有input函数也可以获取,用法与raw_input类型,但是input会将传入的值当作表达式执行,要是不能执行就会报错 python3中获取键盘输入的只有input函数,与python2的raw_input函数功能一样 python的运算符算术运算符:+ - / // % 需要注意的是python的/结果是个浮点数,//类似于其他语言的/,是幂运算,比如10的20次方就是用10*20来表示 赋值运算符 =python中支持同时赋值给多个变量 a,b = 1,2 复合赋值运算符 += -= = /= %= *= //= 用法和其他语言一样 常用的数据类型转换int(x[,base]) 将x转换为一个整数long(x,[,base]) 将x转换为一个长整数float(x) 将x转换到一个浮点数complex(real[,imag]) 创建一个复数str(x) 将对象x转换为字符串repr(x) 将对象x转换为表达式字符串eval(str) 用来计算在字符串中的有效Python表达式,并返回一个对象tuple(s) 将序列s转换为一个元组list(s) 将序列s转换为一个列表chr(x) 将一个整数转换为一个字符unichr(x) 将一个整数转换为unicode字符ord(x) 将一个字符转换为它的整数值hex(x) 将一个整数转换为一个十六进制字符串oct(x) 将一个整数转换为一个八进制字符串 python中的判断if 要判断的条件: 条件成立时,要做的事 例子 从键盘获取自己的年龄,判断是否大于或者等于18岁,如果满足就输出”哥,已成年,网吧可以去了”age = input(“请输入你的年龄”)age = int(age)if age &gt;= 18: print(“哥,已成年,网吧可以去了”)else: print(“你还没有成年,等长大再去网吧吧”) 值得注意的是,input获取到的数据是字符串,需要使用int()函数将获取到值转成int python的关系运算符== != &lt;&gt; &gt; &gt;= &lt; &lt;=其中&lt;&gt;类似于!= python的逻辑运算符and or not python的判断结构有以下几种 1 . if 判断条件: 操作 2. if 判断条件: 操作 else : 操作 3. if 判断条件: 操作 elif 判断条件: 操作 elif 判断条件: 操作 else: 操作 第三种类似于java的 if else if else结构python的判断结构也是可以嵌套的 python的循环结构while 循环条件: 操作用发和其他语言一样 python中的for循环用法为 for 变量名 in 序列python中的for循环可以遍历一切可以遍历的数据python中for和while都可以加上else分支,当没有数据时执行else分支 python中的break和continue关键字用法和java一样break和continue都只能用于循环结构中,并且在循环多层嵌套的情况在,只对最近一层循环有效 python中的字符串在python中,被单引号或者双引号括起来的内容就是字符串.三引号括起来的内容是多行注释 python中的索引和切片索引和其他语言一样,都是从0开始不过python中还有另外一个用法叫切片切片是指对操作的对象截取其中一部分的操作.字符串,列表,元组都支持切片操作切片的语法:[起始:结束:步长]注意:选取的区间属于左闭右开型,即从”起始”位开始,到”结束”位的前一位结束(不包含结束位本身) 比如取字符串前三个字符name = ‘abcdef’print(name[0:3])实现倒序输出name = ‘abcdef’print(name[-1:0:-1]) 字符串常见操作 find检测str是否包含在mystr中,如果是返回开始的索引值,否则返回-1mystr.find(str,start=0,end=len(mystr))如果不指定起始和终点值,默认是查询全部 index跟find()方法一样,只不过如果str不在 mystr中会报一个异常.mystr.index(str,start=0,end=len(mystr)) count返回str在start和end之间 在mystr里面出现的次数mystr.count(str,start=0,end=len(mystr)) replace把mystr中的str1替换成str2,如果count指定,则替换不超过count次.mystr.replace(str1,str2,mystr.count(str1))不指定次数的话,默认是将mystr中的所有str1都替换成str2 split以str为分隔符切片mystr,如果maxsplit有指定值,则仅分隔maxsplit次mystr.split(str=””,2)指定2则会分隔两次,生成三个子字符串 capitalize把字符串的第一个字符大写mystr.capitalize()“hello”.capitalize() –&gt; Hello title把字符串的每个单词首字母大写“hello world”.title() –&gt; Hello World startswith检查字符串是否以指定字符串开头,是则返回True,否则返回False,区分大小写mystr = ‘hello world’mystr.startswith(‘hello’) –&gt; Truemystr.startswith(‘Hello’) –&gt; False endswith检查字符串是否以指定字符串结束,如果是返回True,否则返回False,区分大小写,用法和startswith一样 lower将字符串中的所有大写字符转换为小写“HELLO world”.lower() –&gt; hello world upper将字符串中的所有小写字符转换为大写“hello world”.upper() –&gt; HELLO WORLD ljust返回一个原字符串左对齐,并使用空格填充至长度width的新字符串mystr.ljust(width)“hello”.ljust(10) –&gt; “hello “ (在右边填充了五个空格) rjust返回一个原字符串右对齐,并使用空格填充至width的新字符串mystr.rjust(width)“hello”.rjust(10) –&gt; “ hello” (在左边填充了五个空格) center返回一个原字符串居中,并使用空格填充至长度width的新字符串mystr.center(width)“hello”.center(10) –&gt; “ hello “ (在左边填充了两个空格,在右边填充了三个空格) lstrip删除mystr左边的空白字符mystr.lstrip()“ hello”.lstrip() –&gt; “hello” rstrip删除mystr右边的空白字符mystr.rstrip()“hello “.rstrip() –&gt; “hello” strip删除mystr字符串两端的空白字符mystr.strip()“ hello “.strip() –&gt; “hello” rfind类似于find()函数,不过是从右边开始查找mystr.rfind(str,start=0,end=len(mystr)) rindex类似于index()函数,不过是从右边开始查找mystr.rindex(str,start=0,end=len(mystr)) partition把mystr以str分割成三部分,str前,str和str后mystr.partition(str)“hello world python2 and python3”.partition(‘python’) –&gt; (‘hello world ‘,’python’,’2 and python3’) rpartition类似于partition()函数,不过是从右边开始mystr.rpartition()“hello world python2 and python3”.rpartition(‘python’) –&gt; (“hello world python2 and “,”python”,”3”) splitlines按照行分割,返回一个包含各行内容作为元素的列表mystr.splitlines()“hello\nworld”.splitlines() –&gt; [‘hello’,’world’] isalpha如果mystr所有字符都是字母,则返回True,否则返回Falsemystr.isalpha()“abc”.isalpha() –&gt; True“123”.isalpha() –&gt; False isdigit如果mystr只包含数字则返回True,否则返回Falsemystr.isdigit()“abc”.isdigit() –&gt; False“123”.isdigit() –&gt; True isalnum如果mystr所有字符都是字母或者数字,则返回True,否则返回Falsemystr.isalnum()“123”.isalnum() –&gt; True“abc”.isalnum() –&gt; True“123abc”.isalnum() –&gt; True“abc nttt1”.isalnum() –&gt; False isspace如果mystr中只包含空格,则返回True,否则返回Falsemystr.isspace()“ “.isspace() –&gt; True“abc “.isspace() –&gt; False join在列表中的每一个元素后面插入mystr,最后一个元素后面不插入mystr.join(arr)arr = [‘my’,’name’,’is’,’python’]‘ ‘.join(arr) –&gt; ‘my name is python’ python中的列表类似于java中的list和数组的混合体列表的格式变量名=[元素一,元素二,元素三] arr = [1,2,3,4,5,”上山打老虎”]python中的列表元素可以是不同类型的 获取列表中的元素可以通过索引或者切片,索引从0开始arr[0] –&gt; 1 遍历列表通过for循环 for i in arr: print(i) 将会在键盘上将列表中的所有元素依次打印出来 通过while循环length = len(arr) #通过len函数获得列表的长度i = 0 #定义一个计数器,充当索引 while i &lt; length: print(arr[i]) i += 1 #计数器加1,直到超过len,结束循环 也会依次打印列表中的元素 python列表的相关操作列表中存放的数据是可以进行操作的,例如”增”,”删”,”改” 增加元素append通过append可以向列表添加元素 arr = [1,2,3,4] arr.append(5) for i in arr: print(i) append添加的元素会在列表后面追加 extend通过extend可以将另一个集合中的元素逐以添加到列表中arr2 = [6,6]arr.append(arr2) #直接append列表,会把列表当作一个元素加入arr.extend(arr2) #用extend可以将arr2中的元素一个一个添加到arr中 insert在指定位置index前插入元素object 用法:arr.insert(index,object)a = [0,1,2]a.insert(1,3) #在索引1位置插入3 结果为[0,3,1,2] 修改元素通过下标来确定要修改的是哪个元素,然后进行修改arr = [0,1,2]arr[1] = 3 #将列表arr索引1位置的元素修改为3 结果为[0,3,2] 查找元素in 如果列表中存在该元素,则返回True,否则返回Falsenot in 如果列表中不存在该元素,则返回True,否则返回False 用法arr = [1,2,3]if 1 in arr: #判断arr中存在1不 print(“有”)if 1 not in arr: #判断arr中不存在1不 print(“没有”) #结果是有 在列表中也可以用index和count方法,用法和字符串中的相同arr = [1,2,3]arr.index(1) #获得列表arr中元素值为1的索引,结果是0arr.count(1) #获得列表arr中元素值为1出现的次数.结果是1 删除元素del 根据下标进行删除pop 删除最后一个元素remove 根据元素的值进行删除 arr = [1,2,3,4,5]del arr[0] #删除了列表中的索引0处的元素 结果为[2,3,4,5]arr.pop() #删除了列表中的最后一个元素 结果为[2,3,4]arr.remove(3) #删除列表中元素值为3的元素 结果为[2,4] (列表中如果有多个要删除的元素,只会删除从左边起第一个匹配到的元素) 列表排序sort sort方法是将list按特定顺序重新排列,默认为从小到大,参数reverse=True,可改为倒序,由大到小reverse方法是将list逆置 arr = [1,4,3,2]a.reverse() #将列表反转,结果为 [2,3,4,1]a.sort() #将列表从小到大排列,结果为 [1,2,3,4]a.sort(reverse=True) #将列表从大到小排列,结果为 [4,3,2,1] 列表的嵌套列表中的元素又是一个列表,那么这就是列表的嵌套直接访问列表中的列表可以像java中访问二维数组一样arr = [[1,2],[3,4],[5,6]]arr[0][0] #访问外面列表的第一个元素列表中的第一个元素,结果为1 元组元组与列表类似,不过元组中的数据是不可以更改的,使用小括号括起来的是元组,列表是使用中括号括起来的aTuple = (1,2) 访问元组中的数据和访问列表一样,指定索引就行,索引从0开始aTuple[0] #访问元组索引为0处的元素 结果为1 一旦定义了元组,元组内的数据就不可以更改了,增加删除修改都不可以 元组的内置函数有count,index,用法与列表和字符串相同aTuple.index(1) #获取元素值为1的索引,当有多个元素值为1时,返回从左起,匹配的第一个 结果为0aTuple.count(1) #获取元组中元素值为1的个数 结果为1 字典python的字典类似于java中的map,由键值对组成,用花括号括起来,键值对用:隔开,键值对之间用,隔开dict = {“a”:1,”b”:2,”c”,3} 获取字典中的值,不像元组和列表那样使用索引,而是使用键dict[“a”] #获取字典中键为a的值 结果为1 若访问不存在的键,则会报错如 dict[“d”] #因为字典中不存在d这个键,所以这样写会报错 当我们不确定字典中有没有这个键的时候,可以使用get方法,不会报错v = dict.get(“d”) #字典中没有d这个键,用get方法获取到的值v,是Nonetype(v) #结果是使用get方法的时候还可以设置默认值,当指定的键不存在时,就会返回默认值v = dict.get(“d”,4) #因为dict字典中没有d这个键,而又设置了默认值为4,则v的值为4 字典的操作修改元素列表是通过索引确定元素进而进行修改,字典是通过键确定元素然后进行修改dict[“a”] = 5 #修改字典中键为a的值为5,则字典为 {“a”:5.”b”:2,”c”,3}列表中对不存在的索引进行修改会报错,而字典对不存在的键进行修改操作(不如说是赋值操作),会将这个不存在的键和值添加到字典中 删除元素del 删除指定的元素或者删除字典clear() 清空字典中的元素 del dict[“a”] #会将字典中键为a的元素删除del dict 直接删除dict字典,再次访问会报错dict.clear() #清空字典,删除字典中的所有元素,但是字典dict还是存在的 可以访问 结果为{} 字典的常用方法 len获取字典中的键值对个数dict = {“a”:1,”b”:2,”c”:3}len(dict) #结果为3 keys返回一个包含字典所有key值的列表dict.keys() #结果为 [“a”,”b”,”c”] values返回一个包含字典所有value的列表dict.values() #结果为[1,2,3] items返回一个包含所有(键,值)元组的列表dict.items() #结果为[(“a”,1),(“b”,2),(“c”,3)] has_key如果key在字典中,返回True,否则返回Falsedict.has_key(“a”) #有a这个键,返回Truedict.has_key(“d”) #没有d这个键,返回False python中的遍历通过for xx in yyy: 的语法结构,可以遍历字符串,列表,元组,字典等数据结构 字典的遍历 遍历字典的key(键)for key in dict.keys(): print(key) #结果是a b c 遍历字典的value(值)for value in dict.values(): print(value) #结果是1 2 3 遍历字典的项(元素)for item in dict.items(): print(item) #结果是(“a”,1) (“b”,2) (“c”,3) 遍历字典的key-value(键值对)for key,value in dict.items(): print(“key=%s,value=%s”%(key,value)) #结果是 key=a,value=1 key=b,value=2 key=c,value=3 如何实现带索引的遍历 使用计数器充当索引arr = [1,2,3,4,5]i = 0for a in arr: print(“%d,%d”%(i,a)) 使用enumerate()方法for i,a in enumerate(arr): print(“%d,%d”%(i,a)) 公共方法运算符 python表达式 结果 描述 支持的数据类型 + [1,2]+[3,4] [1,2,3,4] 合并 字符串,列表,元组 * &quot;Hi!&quot; * 4 [&quot;Hi!&quot;,&quot;Hi!&quot;,&quot;Hi!&quot;,&quot;Hi&quot;] 复制 字符串,列表,元组 in 3 in (1,2,3) True 元素是否存在 字符串,列表,元组,字典 not in 4 not in (1,2,3) True 元素是否不存在 字符串,列表,元组,字典 python内置函数cmp(item1,item2) 比较两个元素值len(item) 计算容器中元素个数max(item) 返回容器中元素最大值min(item) 返回容器中元素最小值del(item) 删除变量注意:cmp在比较字典数据时,先比较键,再比较值. cmp函数是通过ascII码进行比较的 len在操作字典数据时,返回的是键值对个数 del方法可以不加空格 直接del item python中的引用和java一样python中可以通过id()方法判断两个元素是否是同一个 可变类型与不可变类型可变类型,值可以改变: 列表 字典不可变类型,值不可以改变: 数值类型(int long boolean float) 字符串 元组 python中的函数定义函数 def 函数名(): 代码 def printStr(): print(“Hello world”)调用函数 直接函数名() 调用 printStr() 函数的文档注释在函数代码块第一行写的字符串会被认为是文档注释def add(a,b): “打印两个数的和” print(“和为%d”%(a+b)) 通过help()方法可以获得函数的文档注释help(add) python的函数和java函数 除了定义写法不同,其他都一样定义带参数的函数,传入参数时要是不指定传给具体的形参,传入的值按照形参的顺序依次赋值add(1,2) 1–&gt;a 2–&gt;badd(b=2,a=1) 可以这样给具体的形参赋值add(b=2,1) 当指定具体的形参了,后面的参数都需要指定 不然会报错SyntaxError: positional argument follows keyword argument 函数的返回值def add(a,b) return a+b在函数内部使用return关键字返回了一个值,那么这个函数就有返回值了,可以在调用的时候定义一个变量接收sum = add(1,2) sum的值为3 函数嵌套 在函数内部还可以调用其他函数 python中的局部变量和全局变量和java中的相仿当在方法中相用全局变量时,需要在变量名前加上global关键字,以标明这个变量是全局变量 在函数中不加global无法修改全局变量的原因是,在函数内部无法更改全局变量的指向..所以可变数据类型不加global也可以进行修改,以为地址值并不会改变 而不可变类型值改变就是地址值改变,所以要加上global python中的函数可以返回多个值,本质是返回了一个元组,元组中的元素是这多个值 python中还可以声明缺省参数,当没有为该形参传入值时,使用默认值def printInfo(name,age=25): print(“name:%s”%name) print(“age:%s”%age) printInfo(“小王”) #因为没有为age传入值,所以使用默认值25 打印 小王 25printInfo(“小吴”,20) #age形参传入了参数,使用传入的参数 打印 小吴 20 需要注意的是,缺省参数后面不能跟没有默认值的形参,不然会报错 所以缺省参数都会放在最后面def printInfo(name,age=25,phone) print.. 上面定义的函数会报错 ,因为在缺省参数后面有没有定义缺省值的参数 python的不定长参数的意义同java的可变参数一样,不过python的不定长参数比java的复杂的多def fun(a,b,c,**d) 接收普通参数,所有参数形成一个元组 **接收键值对,所有参数形成一个字典 fun(1,2,3,4,5,a=1,b=2,c=3) 形参c为(3,4,5) 形参d为{“a”:1,”b”:2,”c”:3} 最前面两个参数1,2赋值给a,b t = (1,1,1)f = {“a”:1,”b”:2}fun(1,2,t,f)fun(1,2,t,f) 上面两种直接传入元组和字典的方式第一种 指定了t是传个元组的,f是传给字典的,所以c = t d = f第二种 没有指定,又t和f都是普通参数 不是键值对 所以 c = (t,f) 而d为空 python中参数传递类似与javapython中的不可变类型传递类似于java中的基本数据类型,所以是值传递python中的可变类型传递类似于java中的引用数据类型,所以是引用传递(本质也是值传递) python中的匿名函数用lambda关键字能创建小型匿名函数.匿名函数主要是省略了def声明函数语法:lambda [arg1[,arg2,…argn]]:expression如下案例sum = lambda arg1,arg2:arg1 + arg2lambda函数能接收任何数量的参数 但只能返回一个表达式的值匿名函数不能直接调用print,因为lambda需要一个表达式]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[lucene学习]]></title>
      <url>%2F2016%2F09%2F11%2Fsolr%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[lucene学习]]></title>
      <url>%2F2016%2F09%2F11%2Flucene%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[什么是luceneLucene是简单而功能强大的基于Java的搜索库。它可以用于任何应用程序来搜索功能。 Lucene是开源项目。它是可扩展的，高性能的库用于索引和搜索几乎任何类型的文本。 Lucene库提供了所需的任何搜索应用程序的核心业务。索引和搜索。 lucene的工作原理 获取原始内容 任何搜索应用程序的第一个步骤是收集在其上的搜索是要进行的目标内容。 构建文档 下一步是建立从原始内容的搜索应用程序可以理解和容易理解的文件。 分析文档 在索引过程启动，该文件是要分析作为其文本部分是一个候选索引。这个过程被称为分析文档。 索引文件 一旦文档被构建和分析，下一步是将索引它们使得该文件可被检索 lucene的主要jar包 基本的lucene操作public class TestLucene { /** * 生成索引库 * * @throws IOException */ @Test public void testLuceneGenerateIndex() throws IOException { //指定索引存放的路径 Directory directory = FSDirectory.open(new File(&quot;D:\\index&quot;)); //创建一个标准分析器 Analyzer analyzer = new StandardAnalyzer(); //创建indexwriterconfig对象 //第一个参数,lucene版本信息,可以使用latest代表最新版本,也可以直接指定 //第二个参数,分析器对象 IndexWriterConfig config = new IndexWriterConfig(Version.LATEST, analyzer); //创建indexwriter对象 IndexWriter writer = new IndexWriter(directory, config); //原始文档的路径 File dir = new File(&quot;D:\\sql语句&quot;); for (File file : dir.listFiles()) { //文件名 String name = file.getName(); //文件大小 long size = FileUtils.sizeOf(file); //文件路径 String path = file.getPath(); //文件内容 String content = FileUtils.readFileToString(file); //创建文件名域 //第一个参数 域的名称 //第二个参数 域的内容 //第三个参数 是否存储 Field nameField = new TextField(&quot;filename&quot;, name, Field.Store.YES); //创建文件大小域 Field sizeField = new LongField(&quot;filesize&quot;, size, Field.Store.YES); //创建文件路径域(不分析 不索引 只存储) Field pathField = new StoredField(&quot;pathField&quot;, path); //创建文件内容域 Field contentField = new TextField(&quot;filecontent&quot;, content, Field.Store.YES); //创建Document对象 Document document = new Document(); document.add(nameField); document.add(sizeField); document.add(pathField); document.add(contentField); //创建索引,并写入索引库 writer.addDocument(document); } writer.close(); } /** * 查询索引库 */ @Test public void testLuceneQueryIndex() throws IOException { //指定索引库存放的路径 Directory directory = FSDirectory.open(new File(&quot;D:\\index&quot;)); //创建indexReader对象 IndexReader reader = DirectoryReader.open(directory); //创建indexSearch对象 IndexSearcher searcher = new IndexSearcher(reader); //创建查询 //Term对象第一个参数是field的name值,第二个参数是具体查询的词 Query query = new TermQuery(new Term(&quot;filecontent&quot;, &quot;select&quot;)); //执行查询 //第一个参数是查询对象,第二个参数是查询结果返回的个数 TopDocs topDocs = searcher.search(query, 10); //遍历查询结果 for (ScoreDoc scoreDoc : topDocs.scoreDocs) { //scoredoc对象的doc属性就是document对象的id //根据对象id获取对象 Document document = searcher.doc(scoreDoc.doc); System.out.println(document.get(&quot;filename&quot;)); System.out.println(document.get(&quot;filesize&quot;)); System.out.println(document.get(&quot;pathField&quot;)); } reader.close(); } //标准分析器的分词效果 @Test public void testStandardAnalyzer() throws IOException { //创建一个标准分析器对象 Analyzer analyzer = new StandardAnalyzer(); //获得tokenStream对象 //第一个参数,域名,可以随便给一个 //第二个参数,要分析的文本内容 TokenStream tokenStream = analyzer.tokenStream(&quot;test&quot;, &quot;The Spring Framework provides a comprehensive programming and configuration model.&quot;); //添加一个引用,可以获得每个关键词 CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class); //添加一个偏移量的引用,记录关键词的起始位置 OffsetAttribute offsetAttribute = tokenStream.addAttribute(OffsetAttribute.class); //将指针调整到列表的头部 tokenStream.reset(); //遍历关键词裂变,通过incrementToken方法判断列表是否结束 while (tokenStream.incrementToken()) { //关键词的起始位置 System.out.println(offsetAttribute.startOffset()); //关键词 System.out.println(charTermAttribute); //关键词的结束位置 System.out.println(offsetAttribute.endOffset()); } tokenStream.close(); } //IKAnalyzer的分词效果 @Test public void testIKAnalyzer() throws IOException { //创建一个标准分析器对象 Analyzer analyzer = new IKAnalyzer(); //获得tokenStream对象 //第一个参数,域名,可以随便给一个 //第二个参数,要分析的文本内容 TokenStream tokenStream = analyzer.tokenStream(&quot;test&quot;, &quot;&lt;&lt;我的狐仙老婆&gt;&gt;是一部17K小说网连载的仙侠网络小说,作者是黑夜de白羊.主要讲述了高富帅刘弈,因为被仙女封印了一只调皮狡猾的俏狐仙在他的右手中,从此走上了不平凡的修仙之路的故事.&quot;); //添加一个引用,可以获得每个关键词 CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class); //添加一个偏移量的引用,记录关键词的起始位置 OffsetAttribute offsetAttribute = tokenStream.addAttribute(OffsetAttribute.class); //将指针调整到列表的头部 tokenStream.reset(); //遍历关键词裂变,通过incrementToken方法判断列表是否结束 while (tokenStream.incrementToken()) { //关键词的起始位置 System.out.println(offsetAttribute.startOffset()); //关键词 System.out.println(charTermAttribute); //关键词的结束位置 System.out.println(offsetAttribute.endOffset()); } tokenStream.close(); } //索引库的添加 @Test public void testAddLuceneIndex() throws IOException { //索引库存放路径 IndexWriter writer = getIndexWriter(); Document document = new Document(); document.add(new TextField(&quot;filename&quot;, &quot;新添加的文档名&quot;, Field.Store.YES)); document.add(new TextField(&quot;content&quot;, &quot;新添加的文档内容&quot;, Field.Store.NO)); document.add(new TextField(&quot;content&quot;, &quot;新添加的文档内容第二个content&quot;, Field.Store.YES)); document.add(new TextField(&quot;content1&quot;, &quot;新添加的文档内容能看到的&quot;, Field.Store.YES)); //添加文档到索引库 writer.addDocument(document); //关闭IndexWriter writer.close(); } //删除索引库中的全部索引(慎用) @Test public void testDeleteLuceneIndexRepository() throws IOException { IndexWriter writer = getIndexWriter(); writer.deleteAll(); writer.close(); } private static IndexWriter getIndexWriter() throws IOException { Directory directory = FSDirectory.open(new File(&quot;D:\\index&quot;)); IndexWriterConfig config = new IndexWriterConfig(Version.LATEST, new IKAnalyzer()); return new IndexWriter(directory, config); } //指定查询条件删除索引 @Test public void testConditionDeleteLuceneIndex() throws IOException { IndexWriter indexWriter = getIndexWriter(); //创建一个查询条件 Query query = new TermQuery(new Term(&quot;filename&quot;, &quot;apache&quot;)); //根据查询条件删除 indexWriter.deleteDocuments(query); //关流 indexWriter.close(); } //索引库的修改,原理就是先删除后修改 @Test public void testUpdateLuceneIndexRepository() throws IOException { IndexWriter indexWriter = getIndexWriter(); //创建一个document对象 Document document = new Document(); document.add(new TextField(&quot;filename&quot;, &quot;要更新的文件名&quot;, Field.Store.YES)); document.add(new TextField(&quot;filecontent&quot;, &quot;要更新的文档内容,...(省略一万字)&quot;, Field.Store.YES)); indexWriter.updateDocument(new Term(&quot;content&quot;, &quot;java&quot;), document); indexWriter.close(); } } Lucene索引库的查询对象对要搜索的信息创建Query查询对象，Lucene会根据Query查询对象生成最终的查询语法，类似关系数据库Sql语法一样，Lucene也有自己的查询语法，比如：“name:lucene”表示查询Field的name为“lucene”的文档信息。 可以通过两种方式创建查询对象： 使用Lucene提供的Query子类Query是一个抽象类，Lucene提供了很多查询子类，比如TermQuery精确查询，NumericRangeQuery数值范围查询如下代码： Query query = new TermQuery(new Term(&quot;name&quot;,&quot;lucene&quot;)) 使用QueryParser解析查询表达式QueryParser会将用户输入的查询表达式解析成Query对象实例如下代码： QueryParser parser = new QueryParser(&quot;name&quot;,new IKAnalyzer()); Query query = parser.parse(&quot;name:lucene&quot;) 具体的查询操作使用Query的子类对象MatchAllDocs对象使用MatchAllDocQuery查询索引目录中的所有文档 @Test public void testMatchAllDocsQuery() throws Exception { IndexSearcher indexSearcher = getIndexSearcher(); //创建查询条件 Query query = new MatchAllDocsQuery(); //执行查询 printResult(query, indexSearcher); } TermQueryTermQuery，通过项查询，TermQuery不使用分析器所以建议匹配不分词的Field域查询，比如订单号、分类ID号等。指定要查询的域和要查询的关键词。 //使用Termquery查询 @Test public void testTermQuery() throws Exception { IndexSearcher indexSearcher = getIndexSearcher(); //创建查询对象 Query query = new TermQuery(new Term(&quot;content&quot;, &quot;lucene&quot;)); //执行查询 TopDocs topDocs = indexSearcher.search(query, 10); //共查询到的document个数 System.out.println(&quot;查询结果总数量：&quot; + topDocs.totalHits); //遍历查询结果 for (ScoreDoc scoreDoc : topDocs.scoreDocs) { Document document = indexSearcher.doc(scoreDoc.doc); System.out.println(document.get(&quot;filename&quot;)); //System.out.println(document.get(&quot;content&quot;)); System.out.println(document.get(&quot;path&quot;)); System.out.println(document.get(&quot;size&quot;)); } //关闭indexreader indexSearcher.getIndexReader().close(); } NumericRangeQuery可以根据数值范围查询。 /** * 封装结果打印 */ private void printResult(IndexSearcher indexSearcher, Query query) throws Exception { //查询索引库 TopDocs topDocs = indexSearcher.search(query, 100); ScoreDoc[] scoreDocs = topDocs.scoreDocs; System.out.println(&quot;查询结果总记录数：&quot; + topDocs.totalHits); //遍历查询结果 for (ScoreDoc scoreDoc : scoreDocs) { int docId = scoreDoc.doc; //通过id查询文档对象 Document document = indexSearcher.doc(docId); //取属性 System.out.println(document.get(&quot;name&quot;)); System.out.println(document.get(&quot;size&quot;)); System.out.println(document.get(&quot;content&quot;)); System.out.println(document.get(&quot;path&quot;)); } //关闭索引库 indexSearcher.getIndexReader().close(); } //数值范围查询 @Test public void testNumericRangeQuery() throws Exception { IndexSearcher indexSearcher = getIndexSearcher(); //创建查询 //参数： //1.域名 //2.最小值 //3.最大值 //4.是否包含最小值 //5.是否包含最大值 Query query = NumericRangeQuery.newLongRange(&quot;size&quot;, 1l, 1000l, true, true); //执行查询 printResult(query, indexSearcher); } BooleanQuery可以组合查询条件。 //组合条件查询 @Test public void testBooleanQuery() throws Exception { IndexSearcher indexSearcher = getIndexSearcher(); //创建一个布尔查询对象 BooleanQuery query = new BooleanQuery(); //创建第一个查询条件 Query query1 = new TermQuery(new Term(&quot;filename&quot;, &quot;apache&quot;)); Query query2 = new TermQuery(new Term(&quot;content&quot;, &quot;apache&quot;)); //组合查询条件 query.add(query1, Occur.MUST); query.add(query2, Occur.MUST); //执行查询 printResult(query, indexSearcher); } Occur.MUST：必须满足此条件，相当于andOccur.SHOULD：应该满足，但是不满足也可以，相当于orOccur.MUST_NOT：必须不满足。相当于not 使用queryparser查询通过QueryParser也可以创建Query，QueryParser提供一个Parse方法，此方法可以直接根据查询语法来查询。Query对象执行的查询语法可通过System.out.println(query);查询。需要使用到分析器。建议创建索引时使用的分析器和查询索引时使用的分析器要一致。 程序实现 @Test public void testQueryParser() throws Exception { IndexSearcher indexSearcher = getIndexSearcher(); //创建queryparser对象 //第一个参数默认搜索的域 //第二个参数就是分析器对象 QueryParser queryParser = new QueryParser(&quot;content&quot;, new IKAnalyzer()); Query query = queryParser.parse(&quot;Lucene是java开发的&quot;); //执行查询 printResult(query, indexSearcher); } 查询语法 基础的查询语法，关键词查询：域名+“：”+搜索的关键字例如：content:java 范围查询域名+“:”+[最小值 TO 最大值]例如：size:[1 TO 1000]范围查询在lucene中不支持数值类型，支持字符串类型。在solr中支持数值类型。 组合条件查询1）+条件1 +条件2：两个条件之间是并且的关系and例如：+filename:apache +content:apache 2）+条件1 条件2：必须满足第一个条件，应该满足第二个条件例如：+filename:apache content:apache 3）条件1 条件2：两个条件满足其一即可。例如：filename:apache content:apache 4）-条件1 条件2：必须不满足条件1，要满足条件2例如：-filename:apache content:apacheOccur.MUST 查询条件必须满足，相当于and +（加号）Occur.SHOULD 查询条件可选，相当于or 空（不用符号）Occur.MUST_NOT 查询条件不能满足，相当于not非 -（减号） 第二种写法：条件1 AND 条件2条件1 OR 条件2条件1 NOT 条件2 MulitFieldQueryParser可以指定多个默认搜索域 @Test public void testMultiFiledQueryParser() throws Exception { IndexSearcher indexSearcher = getIndexSearcher(); //可以指定默认搜索的域是多个 String[] fields = {&quot;filename&quot;, &quot;content&quot;}; //创建一个MulitFiledQueryParser对象 MultiFieldQueryParser queryParser = new MultiFieldQueryParser(fields, new IKAnalyzer()); Query query = queryParser.parse(&quot;java and apache&quot;); System.out.println(query); //执行查询 printResult(query, indexSearcher); }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[商品秒杀功能的分析与基本实现思路]]></title>
      <url>%2F2016%2F05%2F20%2F%E5%95%86%E5%93%81%E7%A7%92%E6%9D%80%E5%8A%9F%E8%83%BD%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF%2F</url>
      <content type="text"><![CDATA[搬运自 http://www.jb51.net/article/77560.htm 一、秒杀业务分析正常电子商务流程 （1）查询商品；（2）创建订单；（3）扣减库存；（4）更新订单；（5）付款；（6）卖家发货 秒杀业务的特性 （1）低廉价格；（2）大幅推广；（3）瞬时售空；（4）一般是定时上架；（5）时间短、瞬时并发量高； 二、秒杀技术挑战假设某网站秒杀活动只推出一件商品，预计会吸引1万人参加活动，也就说最大并发请求数是10000，秒杀系统需要面对的技术挑战有： 对现有网站业务造成冲击秒杀活动只是网站营销的一个附加活动，这个活动具有时间短，并发访问量大的特点，如果和网站原有应用部署在一起，必然会对现有业务造成冲击，稍有不慎可能导致整个网站瘫痪。 解决方案：将秒杀系统独立部署，甚至使用独立域名，使其与网站完全隔离。 高并发下的应用、数据库负载用户在秒杀开始前，通过不停刷新浏览器页面以保证不会错过秒杀，这些请求如果按照一般的网站应用架构，访问应用服务器、连接数据库，会对应用服务器和数据库服务器造成负载压力。 解决方案：重新设计秒杀商品页面，不使用网站原来的商品详细页面，页面内容静态化，用户请求不需要经过应用服务。 突然增加的网络及服务器带宽假设商品页面大小200K（主要是商品图片大小），那么需要的网络和服务器带宽是2G（200K×10000），这些网络带宽是因为秒杀活动新增的，超过网站平时使用的带宽。 解决方案：因为秒杀新增的网络带宽，必须和运营商重新购买或者租借。为了减轻网站服务器的压力，需要将秒杀商品页面缓存在CDN，同样需要和CDN服务商临时租借新增的出口带宽。 直接下单秒杀的游戏规则是到了秒杀才能开始对商品下单购买，在此时间点之前，只能浏览商品信息，不能下单。而下单页面也是一个普通的URL，如果得到这个URL，不用等到秒杀开始就可以下单了。 解决方案：为了避免用户直接访问下单页面URL，需要将改URL动态化，即使秒杀系统的开发者也无法在秒杀开始前访问下单页面的URL。办法是在下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到。 如何控制秒杀商品页面购买按钮的点亮购买按钮只有在秒杀开始的时候才能点亮，在此之前是灰色的。如果该页面是动态生成的，当然可以在服务器端构造响应页面输出，控制该按钮是灰色还 是点亮，但是为了减轻服务器端负载压力，更好地利用CDN、反向代理等性能优化手段，该页面被设计为静态页面，缓存在CDN、反向代理服务器上，甚至用户浏览器上。秒杀开始时，用户刷新页面，请求根本不会到达应用服务器。 解决方案：使用Javascript脚本控制，在秒杀商品静态页面中加入一个Javascript文件引用，该Javascript文件中包含 秒杀开始标志为否；当秒杀开始的时候生成一个新的Javascript文件（文件名保持不变，只是内容不一样），更新秒杀开始标志为是，加入下单页面的URL及随机数参数（这个随机数只会产生一个，即所有人看到的URL都是同一个，服务器端可以用redis这种分布式缓存服务器来保存随机数），并被用户浏览器加载，控制秒杀商品页面的展示。这个Javascript文件的加载可以加上随机版本号（例如xx.js?v=32353823），这样就不会被浏览器、CDN和反向代理服务器缓存。 这个Javascript文件非常小，即使每次浏览器刷新都访问Javascript文件服务器也不会对服务器集群和网络带宽造成太大压力。 如何只允许第一个提交的订单被发送到订单子系统由于最终能够成功秒杀到商品的用户只有一个，因此需要在用户提交订单时，检查是否已经有订单提交。如果已经有订单提交成功，则需要更新 Javascript文件，更新秒杀开始标志为否，购买按钮变灰。事实上，由于最终能够成功提交订单的用户只有一个，为了减轻下单页面服务器的负载压力， 可以控制进入下单页面的入口，只有少数用户能进入下单页面，其他用户直接进入秒杀结束页面。 解决方案：假设下单服务器集群有10台服务器，每台服务器只接受最多10个下单请求。在还没有人提交订单成功之前，如果一台服务器已经有十单了，而有的一单都没处理，可能出现的用户体验不佳的场景是用户第一次点击购买按钮进入已结束页面，再刷新一下页面，有可能被一单都没有处理的服务器处理，进入了填写订单的页面，可以考虑通过cookie的方式来应对，符合一致性原则。当然可以采用最少连接的负载均衡算法，出现上述情况的概率大大降低。 如何进行下单前置检查下单服务器检查本机已处理的下单请求数目：如果超过10条，直接返回已结束页面给用户； 如果未超过10条，则用户可进入填写订单及确认页面； 检查全局已提交订单数目： 已超过秒杀商品总数，返回已结束页面给用户； 未超过秒杀商品总数，提交到子订单系统； 秒杀一般是定时上架该功能实现方式很多。不过目前比较好的方式是：提前设定好商品的上架时间，用户可以在前台看到该商品，但是无法点击“立即购买”的按钮。但是需要考虑的是，有人可以绕过前端的限制，直接通过URL的方式发起购买，这就需要在前台商品页面，以及bug页面到后端的数据库，都要进行时钟同步。越在后端控制，安全性越高。 定时秒杀的话，就要避免卖家在秒杀前对商品做编辑带来的不可预期的影响。这种特殊的变更需要多方面评估。一般禁止编辑，如需变更，可以走数据订正多的流程。 减库存的操作有两种选择，一种是拍下减库存 另外一种是付款减库存；目前采用的“拍下减库存”的方式，拍下就是一瞬间的事，对用户体验会好些。 库存会带来“超卖”的问题：售出数量多于库存数量 由于库存并发更新的问题，导致在实际库存已经不足的情况下，库存依然在减，导致卖家的商品卖得件数超过秒杀的预期。方案：采用乐观锁 update auction_auctions setquantity = #inQuantity#where auction_id = #itemId# and quantity = #dbQuantity# 秒杀器的应对秒杀器一般下单个购买及其迅速，根据购买记录可以甄别出一部分。可以通过校验码达到一定的方法，这就要求校验码足够安全，不被破解，采用的方式有：秒杀专用验证码，电视公布验证码，秒杀答题。 三、秒杀架构原则尽量将请求拦截在系统上游传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小【一趟火车其实只有2000张票，200w个人来买，基本没有人能买成功，请求有效率为0】。 读多写少的常用多使用缓存这是一个典型的读多写少的应用场景【一趟火车其实只有2000张票，200w个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%】，非常适合使用缓存。 四、秒杀架构设计秒杀系统为秒杀而设计，不同于一般的网购行为，参与秒杀活动的用户更关心的是如何能快速刷新商品页面，在秒杀开始的时候抢先进入下单页面，而不是商品详情等用户体验细节，因此秒杀系统的页面设计应尽可能简单。 商品页面中的购买按钮只有在秒杀活动开始的时候才变亮，在此之前及秒杀商品卖出后，该按钮都是灰色的，不可以点击。 下单表单也尽可能简单，购买数量只能是一个且不可以修改，送货地址和付款方式都使用用户默认设置，没有默认也可以不填，允许等订单提交后修改；只有第一个提交的订单发送给网站的订单子系统，其余用户提交订单后只能看到秒杀结束页面。 要做一个这样的秒杀系统，业务会分为两个阶段，第一个阶段是秒杀开始前某个时间到秒杀开始， 这个阶段可以称之为准备阶段，用户在准备阶段等待秒杀； 第二个阶段就是秒杀开始到所有参与秒杀的用户获得秒杀结果， 这个就称为秒杀阶段吧。 前端层设计首先要有一个展示秒杀商品的页面， 在这个页面上做一个秒杀活动开始的倒计时， 在准备阶段内用户会陆续打开这个秒杀的页面， 并且可能不停的刷新页面。这里需要考虑两个问题： 第一个是秒杀页面的展示我们知道一个html页面还是比较大的，即使做了压缩，http头和内容的大小也可能高达数十K，加上其他的css， js，图片等资源，如果同时有几千万人参与一个商品的抢购，一般机房带宽也就只有1G~10G，网络带宽就极有可能成为瓶颈，所以这个页面上各类静态资源首先应分开存放，然后放到cdn节点上分散压力，由于CDN节点遍布全国各地，能缓冲掉绝大部分的压力，而且还比机房带宽便宜~ 第二个是倒计时出于性能原因这个一般由js调用客户端本地时间，就有可能出现客户端时钟与服务器时钟不一致，另外服务器之间也是有可能出现时钟不一致。客户端与服务器时钟不一致可以采用客户端定时和服务器同步时间，这里考虑一下性能问题，用于同步时间的接口由于不涉及到后端逻辑，只需要将当前web服务器的时间发送给客户端就可以了，因此速度很快，就我以前测试的结果来看，一台标准的web服务器2W+QPS不会有问题，如果100W人同时刷，100W QPS也只需要50台web，一台硬件LB就可以了~，并且web服务器群是可以很容易的横向扩展的(LB+DNS轮询)，这个接口可以只返回一小段json格式的数据，而且可以优化一下减少不必要cookie和其他http头的信息，所以数据量不会很大，一般来说网络不会成为瓶颈，即使成为瓶颈也可以考虑多机房专线连通，加智能DNS的解决方案；web服务器之间时间不同步可以采用统一时间服务器的方式，比如每隔1分钟所有参与秒杀活动的web服务器就与时间服务器做一次时间同步。 浏览器层请求拦截（1）产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求;（2）JS层面，限制用户在x秒之内只能提交一次请求; 站点层设计前端层的请求拦截，只能拦住小白用户（不过这是99%的用户哟），高端的程序员根本不吃这一套，写个for循环，直接调用你后端的http请求，怎么整？ （1）同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面 （2）同一个item的查询，例如手机车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面 如此限流，又有99%的流量会被拦截在站点层。 服务层设计站点层的请求拦截，只能拦住普通程序员，高级黑客，假设他控制了10w台肉鸡（并且假设买票不需要实名认证），这下uid的限制不行了吧？怎么整？ （1）大哥，我是服务层，我清楚的知道小米只有1万部手机，我清楚的知道一列火车只有2000张车票，我透10w个请求去数据库有什么意义呢？对于写请求，做请求队列，每次只透过有限的写请求去数据层，如果均成功再放下一批，如果库存不够则队列里的写请求全部返回“已售完”； （2）对于读请求，还用说么？cache来抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的； 如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了。 用户请求分发模块：使用Nginx或Apache将用户的请求分发到不同的机器上。用户请求预处理模块：判断商品是不是还有剩余来决定是不是要处理该请求。用户请求处理模块：把通过预处理的请求封装成事务提交给数据库，并返回是否成功。数据库接口模块：该模块是数据库的唯一接口，负责与数据库交互，提供RPC接口供查询是否秒杀结束、剩余数量等信息。 用户请求预处理模块 经过HTTP服务器的分发后，单个服务器的负载相对低了一些，但总量依然可能很大，如果后台商品已经被秒杀完毕，那么直接给后来的请求返回秒杀失败即可，不必再进一步发送事务了，示例代码可以如下所示： package seckill; import org.apache.http.HttpRequest; /** * 预处理阶段，把不必要的请求直接驳回，必要的请求添加到队列中进入下一阶段. */ public class PreProcessor { // 商品是否还有剩余 private static boolean reminds = true; private static void forbidden() { // Do something. } public static boolean checkReminds() { if (reminds) { // 远程检测是否还有剩余，该RPC接口应由数据库服务器提供，不必完全严格检查. if (!RPC.checkReminds()) { reminds = false; } } return reminds; } /** * 每一个HTTP请求都要经过该预处理. */ public static void preProcess(HttpRequest request) { if (checkReminds()) { // 一个并发的队列 RequestQueue.queue.add(request); } else { // 如果已经没有商品了，则直接驳回请求即可. forbidden(); } } } 并发队列的选择Java的并发包提供了三个常用的并发队列实现，分别是：ConcurrentLinkedQueue 、 LinkedBlockingQueue 和 ArrayBlockingQueue。 ArrayBlockingQueue是初始容量固定的阻塞队列，我们可以用来作为数据库模块成功竞拍的队列，比如有10个商品，那么我们就设定一个10大小的数组队列。 ConcurrentLinkedQueue使用的是CAS原语无锁队列实现，是一个异步队列，入队的速度很快，出队进行了加锁，性能稍慢。 LinkedBlockingQueue也是阻塞的队列，入队和出队都用了加锁，当队空的时候线程会暂时阻塞。 由于我们的系统入队需求要远大于出队需求，一般不会出现队空的情况，所以我们可以选择ConcurrentLinkedQueue来作为我们的请求队列实现： package seckill; import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ConcurrentLinkedQueue; import org.apache.http.HttpRequest; public class RequestQueue { public static ConcurrentLinkedQueue&lt;HttpRequest&gt; queue = new ConcurrentLinkedQueue&lt;HttpRequest&gt;(); } 用户请求模块 package seckill; import org.apache.http.HttpRequest; public class Processor { /** * 发送秒杀事务到数据库队列. */ public static void kill(BidInfo info) { DB.bids.add(info); } public static void process() { BidInfo info = new BidInfo(RequestQueue.queue.poll()); if (info != null) { kill(info); } } } class BidInfo { BidInfo(HttpRequest request) { // Do something. } } 数据库模块 数据库主要是使用一个ArrayBlockingQueue来暂存有可能成功的用户请求。 package seckill; import java.util.concurrent.ArrayBlockingQueue; /** * DB应该是数据库的唯一接口. */ public class DB { public static int count = 10; public static ArrayBlockingQueue&lt;BidInfo&gt; bids = new ArrayBlockingQueue&lt;BidInfo&gt;( 10); public static boolean checkReminds() { // TODO return true; } // 单线程操作 public static void bid() { BidInfo info = bids.poll(); while (count-- &gt; 0) { // insert into table Bids values(item_id, user_id, bid_date, other) // select count(id) from Bids where item_id = ? // 如果数据库商品数量大约总数，则标志秒杀已完成，设置标志位reminds = false. info = bids.poll(); } } } 数据库设计基本概念 概念一“单库” 概念二“分片” 分片解决的是“数据量太大”的问题，也就是通常说的“水平切分”。一旦引入分片，势必有“数据路由”的概念，哪个数据访问哪个库。路由规则通常有3种方法： 范围：range 优点：简单，容易扩展 缺点：各库压力不均（新号段更活跃） 哈希：hash 【大部分互联网公司采用的方案二：哈希分库，哈希路由】 优点：简单，数据均衡，负载均匀 缺点：迁移麻烦（2库扩3库数据要迁移） 路由服务：router-config-server 优点：灵活性强，业务与路由算法解耦 缺点：每次访问数据库前多一次查询 概念三“分组” 分组解决“可用性”问题，分组通常通过主从复制的方式实现。 互联网公司数据库实际软件架构是：又分片，又分组（如下图） 设计思路数据库软件架构师平时设计些什么东西呢？至少要考虑以下四点： 如何保证数据可用性；如何提高数据库读性能（大部分应用读多写少，读会先成为瓶颈）；如何保证一致性；如何提高扩展性； 如何保证数据的可用性？解决可用性问题的思路是=&gt;冗余 如何保证站点的可用性？复制站点，冗余站点 如何保证服务的可用性？复制服务，冗余服务 如何保证数据的可用性？复制数据，冗余数据 数据的冗余，会带来一个副作用=&gt;引发一致性问题（先不说一致性问题，先说可用性）。 如何保证数据库“读”高可用？冗余读库 冗余读库带来的副作用？读写有延时，可能不一致 上面这个图是很多互联网公司mysql的架构，写仍然是单点，不能保证写高可用。 如何保证数据库“写”高可用？冗余写库采用双主互备的方式，可以冗余写库带来的副作用？双写同步，数据可能冲突（例如“自增id”同步冲突）,如何解决同步冲突，有两种常见解决方案： 两个写库使用不同的初始值，相同的步长来增加id：1写库的id为0,2,4,6…；2写库的id为1,3,5,7…；不使用数据的id，业务层自己生成唯一的id，保证数据不冲突；实际中没有使用上述两种架构来做读写的“高可用”，采用的是“双主当主从用”的方式： 仍是双主，但只有一个主提供服务（读+写），另一个主是“shadow-master”，只用来保证高可用，平时不提供服务。 master挂了，shadow-master顶上（vip漂移，对业务层透明，不需要人工介入）。这种方式的好处： 读写没有延时； 读写高可用； 不足： 不能通过加从库的方式扩展读性能；资源利用率为50%，一台冗余主没有提供服务；那如何提高读性能呢？进入第二个话题，如何提供读性能。 如何扩展读性能提高读性能的方式大致有三种，第一种是建立索引。这种方式不展开，要提到的一点是，不同的库可以建立不同的索引。写库不建立索引； 线上读库建立线上访问索引，例如uid； 线下读库建立线下访问索引，例如time； 第二种扩充读性能的方式是，增加从库，这种方法大家用的比较多，但是，存在两个缺点： 从库越多，同步越慢； 同步越慢，数据不一致窗口越大（不一致后面说，还是先说读性能的提高）；实际中没有采用这种方法提高数据库读性能（没有从库），采用的是增加缓存。常见的缓存架构如下：上游是业务应用，下游是主库，从库（读写分离），缓存。 实际的玩法：服务+数据库+缓存一套 业务层不直接面向db和cache，服务层屏蔽了底层db、cache的复杂性。为什么要引入服务层，今天不展开，采用了“服务+数据库+缓存一套”的方式提供数据访问，用cache提高读性能。 不管采用主从的方式扩展读性能，还是缓存的方式扩展读性能，数据都要复制多份（主+从，db+cache），一定会引发一致性问题。 如何保证一致性？主从数据库的一致性，通常有两种解决方案： 中间件如果某一个key有写操作，在不一致时间窗口内，中间件会将这个key的读操作也路由到主库上。这个方案的缺点是，数据库中间件的门槛较高（百度，腾讯，阿里，360等一些公司有）。 强制读主上面实际用的“双主当主从用”的架构，不存在主从不一致的问题。 第二类不一致，是db与缓存间的不一致： 常见的缓存架构如上，此时写操作的顺序是： （1）淘汰cache； （2）写数据库； 读操作的顺序是： （1）读cache，如果cache hit则返回； （2）如果cache miss，则读从库； （3）读从库后，将数据放回cache； 在一些异常时序情况下，有可能从【从库读到旧数据（同步还没有完成），旧数据入cache后】，数据会长期不一致。解决办法是“缓存双淘汰”，写操作时序升级为： （1）淘汰cache； （2）写数据库； （3）在经验“主从同步延时窗口时间”后，再次发起一个异步淘汰cache的请求； 这样，即使有脏数据如cache，一个小的时间窗口之后，脏数据还是会被淘汰。带来的代价是，多引入一次读miss（成本可以忽略）。 除此之外，最佳实践之一是：建议为所有cache中的item设置一个超时时间。 如何提高数据库的扩展性？原来用hash的方式路由，分为2个库，数据量还是太大，要分为3个库，势必需要进行数据迁移，有一个很帅气的“数据库秒级扩容”方案。 如何秒级扩容？ 首先，我们不做2库变3库的扩容，我们做2库变4库（库加倍）的扩容（未来4-&gt;8-&gt;16） 服务+数据库是一套（省去了缓存），数据库采用“双主”的模式。 扩容步骤： 第一步，将一个主库提升; 第二步，修改配置，2库变4库（原来MOD2，现在配置修改后MOD4），扩容完成； 原MOD2为偶的部分，现在会MOD4余0或者2；原MOD2为奇的部分，现在会MOD4余1或者3；数据不需要迁移，同时，双主互相同步，一遍是余0，一边余2，两边数据同步也不会冲突，秒级完成扩容！ 最后，要做一些收尾工作： 将旧的双主同步解除； 增加新的双主（双主是保证可用性的，shadow-master平时不提供服务）； 删除多余的数据（余0的主，可以将余2的数据删除掉）； 这样，秒级别内，我们就完成了2库变4库的扩展。 五、大并发带来的挑战请求接口的合理设计一个秒杀或者抢购页面，通常分为2个部分，一个是静态的HTML等内容，另一个就是参与秒杀的Web后台请求接口。 通常静态HTML等内容，是通过CDN的部署，一般压力不大，核心瓶颈实际上在后台请求接口上。这个后端接口，必须能够支持高并发请求，同时，非常重要的一点，必须尽可能“快”，在最短的时间里返回用户的请求结果。为了实现尽可能快这一点，接口的后端存储使用内存级别的操作会更好一点。仍然直接面向MySQL之类的存储是不合适的，如果有这种复杂业务的需求，都建议采用异步写入。 当然，也有一些秒杀和抢购采用“滞后反馈”，就是说秒杀当下不知道结果，一段时间后才可以从页面中看到用户是否秒杀成功。但是，这种属于“偷懒”行为，同时给用户的体验也不好，容易被用户认为是“暗箱操作”。 高并发的挑战：一定要“快”我们通常衡量一个Web系统的吞吐率的指标是QPS（Query Per Second，每秒处理请求数），解决每秒数万次的高并发场景，这个指标非常关键。举个例子，我们假设处理一个业务请求平均响应时间为100ms，同时，系统内有20台Apache的Web服务器，配置MaxClients为500个（表示Apache的最大连接数目）。 那么，我们的Web系统的理论峰值QPS为（理想化的计算方式）： 20*500/0.1 = 100000 （10万QPS） 咦？我们的系统似乎很强大，1秒钟可以处理完10万的请求，5w/s的秒杀似乎是“纸老虎”哈。实际情况，当然没有这么理想。在高并发的实际场景下，机器都处于高负载的状态，在这个时候平均响应时间会被大大增加。 就Web服务器而言，Apache打开了越多的连接进程，CPU需要处理的上下文切换也越多，额外增加了CPU的消耗，然后就直接导致平均响应时间增加。因此上述的MaxClient数目，要根据CPU、内存等硬件因素综合考虑，绝对不是越多越好。可以通过Apache自带的abench来测试一下，取一个合适的值。然后，我们选择内存操作级别的存储的Redis，在高并发的状态下，存储的响应时间至关重要。网络带宽虽然也是一个因素，不过，这种请求数据包一般比较小，一般很少成为请求的瓶颈。负载均衡成为系统瓶颈的情况比较少，在这里不做讨论哈。 那么问题来了，假设我们的系统，在5w/s的高并发状态下，平均响应时间从100ms变为250ms（实际情况，甚至更多）： 20*500/0.25 = 40000 （4万QPS） 于是，我们的系统剩下了4w的QPS，面对5w每秒的请求，中间相差了1w。 然后，这才是真正的恶梦开始。举个例子，高速路口，1秒钟来5部车，每秒通过5部车，高速路口运作正常。突然，这个路口1秒钟只能通过4部车，车流量仍然依旧，结果必定出现大塞车。（5条车道忽然变成4条车道的感觉）。 同理，某一个秒内，20*500个可用连接进程都在满负荷工作中，却仍然有1万个新来请求，没有连接进程可用，系统陷入到异常状态也是预期之内。 其实在正常的非高并发的业务场景中，也有类似的情况出现，某个业务请求接口出现问题，响应时间极慢，将整个Web请求响应时间拉得很长，逐渐将Web服务器的可用连接数占满，其他正常的业务请求，无连接进程可用。 更可怕的问题是，是用户的行为特点，系统越是不可用，用户的点击越频繁，恶性循环最终导致“雪崩”（其中一台Web机器挂了，导致流量分散到其他正常工作的机器上，再导致正常的机器也挂，然后恶性循环），将整个Web系统拖垮。 重启与过载保护如果系统发生“雪崩”，贸然重启服务，是无法解决问题的。最常见的现象是，启动起来后，立刻挂掉。这个时候，最好在入口层将流量拒绝，然后再将重启。如果是redis/memcache这种服务也挂了，重启的时候需要注意“预热”，并且很可能需要比较长的时间。 秒杀和抢购的场景，流量往往是超乎我们系统的准备和想象的。这个时候，过载保护是必要的。如果检测到系统满负载状态，拒绝请求也是一种保护措施。在前端设置过滤是最简单的方式，但是，这种做法是被用户“千夫所指”的行为。更合适一点的是，将过载保护设置在CGI入口层，快速将客户的直接请求返回。 六、作弊的手段：进攻与防守秒杀和抢购收到了“海量”的请求，实际上里面的水分是很大的。不少用户，为了“抢“到商品，会使用“刷票工具”等类型的辅助工具，帮助他们发送尽可能多的请求到服务器。还有一部分高级用户，制作强大的自动请求脚本。这种做法的理由也很简单，就是在参与秒杀和抢购的请求中，自己的请求数目占比越多，成功的概率越高。 这些都是属于“作弊的手段”，不过，有“进攻”就有“防守”，这是一场没有硝烟的战斗哈。 同一个账号，一次性发出多个请求部分用户通过浏览器的插件或者其他工具，在秒杀开始的时间里，以自己的账号，一次发送上百甚至更多的请求。实际上，这样的用户破坏了秒杀和抢购的公平性。 这种请求在某些没有做数据安全处理的系统里，也可能造成另外一种破坏，导致某些判断条件被绕过。例如一个简单的领取逻辑，先判断用户是否有参与记录，如果没有则领取成功，最后写入到参与记录中。这是个非常简单的逻辑，但是，在高并发的场景下，存在深深的漏洞。多个并发请求通过负载均衡服务器，分配到内网的多台Web服务器，它们首先向存储发送查询请求，然后，在某个请求成功写入参与记录的时间差内，其他的请求获查询到的结果都是“没有参与记录”。这里，就存在逻辑判断被绕过的风险。 应对方案： 在程序入口处，一个账号只允许接受1个请求，其他请求过滤。不仅解决了同一个账号，发送N个请求的问题，还保证了后续的逻辑流程的安全。实现方案，可以通过Redis这种内存缓存服务，写入一个标志位（只允许1个请求写成功，结合watch的乐观锁的特性），成功写入的则可以继续参加。 或者，自己实现一个服务，将同一个账号的请求放入一个队列中，处理完一个，再处理下一个。 多个账号，一次性发送多个请求很多公司的账号注册功能，在发展早期几乎是没有限制的，很容易就可以注册很多个账号。因此，也导致了出现了一些特殊的工作室，通过编写自动注册脚本，积累了一大批“僵尸账号”，数量庞大，几万甚至几十万的账号不等，专门做各种刷的行为（这就是微博中的“僵尸粉“的来源）。举个例子，例如微博中有转发抽奖的活动，如果我们使用几万个“僵尸号”去混进去转发，这样就可以大大提升我们中奖的概率。 这种账号，使用在秒杀和抢购里，也是同一个道理。例如，iPhone官网的抢购，火车票黄牛党。 应对方案： 这种场景，可以通过检测指定机器IP请求频率就可以解决，如果发现某个IP请求频率很高，可以给它弹出一个验证码或者直接禁止它的请求： 弹出验证码，最核心的追求，就是分辨出真实用户。因此，大家可能经常发现，网站弹出的验证码，有些是“鬼神乱舞”的样子，有时让我们根本无法看清。他们这样做的原因，其实也是为了让验证码的图片不被轻易识别，因为强大的“自动脚本”可以通过图片识别里面的字符，然后让脚本自动填写验证码。实际上，有一些非常创新的验证码，效果会比较好，例如给你一个简单问题让你回答，或者让你完成某些简单操作（例如百度贴吧的验证码）。直接禁止IP，实际上是有些粗暴的，因为有些真实用户的网络场景恰好是同一出口IP的，可能会有“误伤“。但是这一个做法简单高效，根据实际场景使用可以获得很好的效果。 多个账号，不同IP发送不同请求所谓道高一尺，魔高一丈。有进攻，就会有防守，永不休止。这些“工作室”，发现你对单机IP请求频率有控制之后，他们也针对这种场景，想出了他们的“新进攻方案”，就是不断改变IP。 有同学会好奇，这些随机IP服务怎么来的。有一些是某些机构自己占据一批独立IP，然后做成一个随机代理IP的服务，有偿提供给这些“工作室”使用。还有一些更为黑暗一点的，就是通过木马黑掉普通用户的电脑，这个木马也不破坏用户电脑的正常运作，只做一件事情，就是转发IP包，普通用户的电脑被变成了IP代理出口。通过这种做法，黑客就拿到了大量的独立IP，然后搭建为随机IP服务，就是为了挣钱。 应对方案： 说实话，这种场景下的请求，和真实用户的行为，已经基本相同了，想做分辨很困难。再做进一步的限制很容易“误伤“真实用户，这个时候，通常只能通过设置业务门槛高来限制这种请求了，或者通过账号行为的”数据挖掘“来提前清理掉它们。 僵尸账号也还是有一些共同特征的，例如账号很可能属于同一个号码段甚至是连号的，活跃度不高，等级低，资料不全等等。根据这些特点，适当设置参与门槛，例如限制参与秒杀的账号等级。通过这些业务手段，也是可以过滤掉一些僵尸号。 七、高并发下的数据安全我们知道在多线程写入同一个文件的时候，会存现“线程安全”的问题（多个线程同时运行同一段代码，如果每次运行结果和单线程运行的结果是一样的，结果和预期相同，就是线程安全的）。如果是MySQL数据库，可以使用它自带的锁机制很好的解决问题，但是，在大规模并发的场景中，是不推荐使用MySQL的。秒杀和抢购的场景中，还有另外一个问题，就是“超发”，如果在这方面控制不慎，会产生发送过多的情况。我们也曾经听说过，某些电商搞抢购活动，买家成功拍下后，商家却不承认订单有效，拒绝发货。这里的问题，也许并不一定是商家奸诈，而是系统技术层面存在超发风险导致的。 超发的原因假设某个抢购场景中，我们一共只有100个商品，在最后一刻，我们已经消耗了99个商品，仅剩最后一个。这个时候，系统发来多个并发请求，这批请求读取到的商品余量都是99个，然后都通过了这一个余量判断，最终导致超发。 在上面的这个图中，就导致了并发用户B也“抢购成功”，多让一个人获得了商品。这种场景，在高并发的情况下非常容易出现。 悲观锁思路解决线程安全的思路很多，可以从“悲观锁”的方向开始讨论。 悲观锁，也就是在修改数据的时候，采用锁定状态，排斥外部请求的修改。遇到加锁的状态，就必须等待。 虽然上述的方案的确解决了线程安全的问题，但是，别忘记，我们的场景是“高并发”。也就是说，会很多这样的修改请求，每个请求都需要等待“锁”，某些线程可能永远都没有机会抢到这个“锁”，这种请求就会死在那里。同时，这种请求会很多，瞬间增大系统的平均响应时间，结果是可用连接数被耗尽，系统陷入异常。 FIFO队列思路那好，那么我们稍微修改一下上面的场景，我们直接将请求放入队列中的，采用FIFO（First Input First Output，先进先出），这样的话，我们就不会导致某些请求永远获取不到锁。看到这里，是不是有点强行将多线程变成单线程的感觉哈。 然后，我们现在解决了锁的问题，全部请求采用“先进先出”的队列方式来处理。那么新的问题来了，高并发的场景下，因为请求很多，很可能一瞬间将队列内存“撑爆”，然后系统又陷入到了异常状态。或者设计一个极大的内存队列，也是一种方案，但是，系统处理完一个队列内请求的速度根本无法和疯狂涌入队列中的数目相比。也就是说，队列内的请求会越积累越多，最终Web系统平均响应时候还是会大幅下降，系统还是陷入异常。 乐观锁思路这个时候，我们就可以讨论一下“乐观锁”的思路了。乐观锁，是相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败。这样的话，我们就不需要考虑队列的问题，不过，它会增大CPU的计算开销。但是，综合来说，这是一个比较好的解决方案。 有很多软件和服务都“乐观锁”功能的支持，例如Redis中的watch就是其中之一。通过这个实现，我们保证了数据的安全。 八、总结互联网正在高速发展，使用互联网服务的用户越多，高并发的场景也变得越来越多。电商秒杀和抢购，是两个比较典型的互联网高并发场景。虽然我们解决问题的具体技术方案可能千差万别，但是遇到的挑战却是相似的，因此解决问题的思路也异曲同工。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[net.sf.ehcache.CacheException异常]]></title>
      <url>%2F2016%2F05%2F18%2FehcacheManage%E5%BC%82%E5%B8%B8%E8%A7%A3%E5%86%B3%2F</url>
      <content type="text"><![CDATA[异常及产生原因今天启动项目报了以下错误 PropertyAccessException 1: org.springframework.beans.MethodInvocationException: Property &apos;realm&apos; threw exception; nested exception is org.apache.shiro.cache.CacheException: net.sf.ehcache.CacheException: Another unnamed CacheManager already exists in the same VM. Please provide unique names for each CacheManager in the config or do one of following: 1. Use one of the CacheManager.create() static factory methods to reuse same CacheManager with same name or create one if necessary 2. Shutdown the earlier cacheManager before creating new one with same name. The source of the existing CacheManager is: InputStreamConfigurationSource [stream=java.io.BufferedInputStream@38598a4f] org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;shiroFilter&apos; defined in class path resource [applicationContext.xml]: Cannot resolve reference to bean &apos;securityManager&apos; while setting bean property &apos;securityManager&apos;; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;securityManager&apos; defined in class path resource [applicationContext.xml]: Error setting property values; nested exception is org.springframework.beans.PropertyBatchUpdateException; nested PropertyAccessExceptions (1) are: PropertyAccessException 1: org.springframework.beans.MethodInvocationException: Property &apos;realm&apos; threw exception; nested exception is org.apache.shiro.cache.CacheException: net.sf.ehcache.CacheException: Another unnamed CacheManager already exists in the same VM. Please provide unique names for each CacheManager in the config or do one of following: 1. Use one of the CacheManager.create() static factory methods to reuse same CacheManager with same name or create one if necessary 2. Shutdown the earlier cacheManager before creating new one with same name. The source of the existing CacheManager is: InputStreamConfigurationSource [stream=java.io.BufferedInputStream@38598a4f] at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1481) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1226) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:543) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:240) at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:687) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:523) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:83) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:69) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:48) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:292) at org.junit.runner.JUnitCore.run(JUnitCore.java:157) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:119) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:42) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;securityManager&apos; defined in class path resource [applicationContext.xml]: Error setting property values; nested exception is org.springframework.beans.PropertyBatchUpdateException; nested PropertyAccessExceptions (1) are: PropertyAccessException 1: org.springframework.beans.MethodInvocationException: Property &apos;realm&apos; threw exception; nested exception is org.apache.shiro.cache.CacheException: net.sf.ehcache.CacheException: Another unnamed CacheManager already exists in the same VM. Please provide unique names for each CacheManager in the config or do one of following: 1. Use one of the CacheManager.create() static factory methods to reuse same CacheManager with same name or create one if necessary 2. Shutdown the earlier cacheManager before creating new one with same name. The source of the existing CacheManager is: InputStreamConfigurationSource [stream=java.io.BufferedInputStream@38598a4f] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1518) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1226) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:543) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351) ... 43 more Caused by: org.springframework.beans.PropertyBatchUpdateException; nested PropertyAccessExceptions (1) are: PropertyAccessException 1: org.springframework.beans.MethodInvocationException: Property &apos;realm&apos; threw exception; nested exception is org.apache.shiro.cache.CacheException: net.sf.ehcache.CacheException: Another unnamed CacheManager already exists in the same VM. Please provide unique names for each CacheManager in the config or do one of following: 1. Use one of the CacheManager.create() static factory methods to reuse same CacheManager with same name or create one if necessary 2. Shutdown the earlier cacheManager before creating new one with same name. The source of the existing CacheManager is: InputStreamConfigurationSource [stream=java.io.BufferedInputStream@38598a4f] at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:121) at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:75) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1514) ... 51 more 之前项目运行一直没问题,今天往项目中整合了activiti,运行activiti测试案例就报了上面的错.根据异常信息可以得出是缓存管理器出了问题..ehcache缓存是在项目整合shiro加入的,配置如下 &lt;!--配置安全管理器--&gt; &lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt; &lt;!--注入缓存管理器--&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot;/&gt; &lt;!--在安全管理器中配置自定义的Realm类--&gt; &lt;property name=&quot;realm&quot; ref=&quot;contextRealm&quot;/&gt; &lt;/bean&gt; &lt;!--缓存管理器--&gt; &lt;bean id=&quot;cacheManager&quot; scope=&quot;singleton&quot; class=&quot;org.apache.shiro.cache.ehcache.EhCacheManager&quot;&gt; &lt;property name=&quot;cacheManagerConfigFile&quot; value=&quot;classpath:ehcache.xml&quot;/&gt; &lt;/bean&gt; 解决方法由异常信息可以看出,内存中已经有一个ehcacheManager了,现在又试图根据相同的配置文件生成一个新的ehcacheManager,进而报错 解决该异常方法如下 在项目中新增如下依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; 依赖版本根据项目spring环境选择 然后更改缓存管理器配置如下 &lt;!--配置安全管理器--&gt; &lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt; &lt;!--注入缓存管理器--&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;cacheManager&quot;/&gt; &lt;!--在安全管理器中配置自定义的Realm类--&gt; &lt;property name=&quot;realm&quot; ref=&quot;contextRealm&quot;/&gt; &lt;/bean&gt; &lt;!--缓存管理器--&gt; &lt;bean id=&quot;cacheManager&quot; scope=&quot;singleton&quot; class=&quot;org.apache.shiro.cache.ehcache.EhCacheManager&quot;&gt; &lt;property name=&quot;cacheManager&quot; ref=&quot;ehcache&quot;/&gt; &lt;/bean&gt; &lt;!--缓存工厂--&gt; &lt;bean id=&quot;ehcache&quot; class=&quot;org.springframework.cache.ehcache.EhCacheManagerFactoryBean&quot;&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:ehcache.xml&quot;/&gt; &lt;property name=&quot;shared&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; 核心是新增一个缓存工厂bean,设置其shared属性为true.这个配置的含义是当运行时有地方需要缓存管理器时,直接使用当前的就行,不需要新生成,也就不会报上面的错了.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[activeMq数据持久化]]></title>
      <url>%2F2016%2F04%2F21%2FactiveMq%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
      <content type="text"><![CDATA[ActiveMQ数据持久化总共有三种方式, 默认文件存储 在kahadb中 还可以保存在mysql和oracle中 对于点对点的方式, 数据存储会自动进行持久化.对于发布/订阅方式,需要通过代码进行设置. 并且保证已经连通过了一次, 否则消费者无法接收到信息. 发布/订阅发布者设置持久化模式 发布/订阅消费者获取信息 设置消费者id,并且保证每一个消费者id唯一. 通过mysql保存数据信息把mysql的驱动jar包放到amq的lib目录下到amq/conf中, 修改activemq.xml文件注释掉 &lt;persistenceAdapter&gt; &lt;kahaDB directory=&quot;${activemq.base}/data/kahadb&quot;/&gt; &lt;/persistenceAdapter&gt; 改为 &lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataDirectory=&quot;${activemq.base}/data&quot; dataSource=&quot;#derby-ds&quot;/&gt; &lt;/persistenceAdapter&gt; 同时在后面加上 &lt;bean id=&quot;derby-ds&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost/activemq?relaxAutoCommit=true&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;activemq&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;activemq&quot;/&gt; &lt;property name=&quot;maxActive&quot; value=&quot;200&quot;/&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; 在mysql中创建activemq数据库 启动mysql这样就会产生三张与activemq相关的表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[activeMq服务器搭建]]></title>
      <url>%2F2016%2F04%2F20%2FactiveMQ%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[activeMq服务器搭建 下载ActiveMQ 配置jdk环境 解压activeMQ安装包 运行使用bin目录下的activemq命令启动：[root@localhost bin]# ./activemq start关闭：[root@localhost bin]# ./activemq stop查看状态：[root@localhost bin]# ./activemq status 访问activeMQ默认帐号密码 admin admin]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[solr集群版搭建]]></title>
      <url>%2F2016%2F04%2F15%2Fsolr%E9%9B%86%E7%BE%A4%E7%89%88%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[Solr集群的搭建第一步：创建四个tomcat实例。每个tomcat运行在不同的端口。8180、8280、8380、8480 第二步：部署solr的war包。把单机版的solr工程复制到集群中的tomcat中。 第三步：为每个solr实例创建一个对应的solrhome。使用单机版的solrhome复制四份。 第四步：需要修改solr的web.xml文件。把solrhome关联起来。 第五步：配置solrCloud相关的配置。每个solrhome下都有一个solr.xml，把其中的ip及端口号配置好。 第六步：让zookeeper统一管理配置文件。需要把solrhome/collection1/conf目录上传到zookeeper。上传任意solrhome中的配置文件即可。 使用工具上传配置文件：/root/solr-4.10.3/example/scripts/cloud-scripts/zkcli.sh ./zkcli.sh -zkhost 192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183 -cmd upconfig -confdir /usr/local/solr-cloud/solrhome01/collection1/conf -confname myconf 查看zookeeper上的配置文件：使用zookeeper目录下的bin/zkCli.sh命令查看zookeeper上的配置文件： [root@localhost bin]# ./zkCli.sh [zk: localhost:2181(CONNECTED) 0] ls / [configs, zookeeper] [zk: localhost:2181(CONNECTED) 1] ls /configs [myconf] [zk: localhost:2181(CONNECTED) 2] ls /configs/myconf [admin-extra.menu-top.html, currency.xml, protwords.txt, mapping-FoldToASCII.txt, _schema_analysis_synonyms_english.json, _rest_managed.json, solrconfig.xml, _schema_analysis_stopwords_english.json, stopwords.txt, lang, spellings.txt, mapping-ISOLatin1Accent.txt, admin-extra.html, xslt, synonyms.txt, scripts.conf, update-script.js, velocity, elevate.xml, admin-extra.menu-bottom.html, clustering, schema.xml] [zk: localhost:2181(CONNECTED) 3] 退出： [zk: localhost:2181(CONNECTED) 3] quit 第七步：修改tomcat/bin目录下的catalina.sh 文件，关联solr和zookeeper。把此配置添加到配置文件中： JAVA_OPTS=&quot;-DzkHost=192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183&quot; 第八步：启动每个tomcat实例。要包装zookeeper集群是启动状态。 第九步：访问集群 第十步：创建新的Collection进行分片处理。http://192.168.25.154:8180/solr/admin/collectionsaction=CREATE&amp;name=collection2&amp;numShards=2&amp;replicationFactor=2 第十一步：删除不用的Collection。http://192.168.25.154:8180/solr/admin/collections?action=DELETE&amp;name=collection1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[solr单机版搭建]]></title>
      <url>%2F2016%2F04%2F15%2Fsolr%E5%8D%95%E6%9C%BA%E7%89%88%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[solr安装第一步：把solr 的压缩包上传到Linux系统 第二步：解压solr。 第三步：安装Tomcat，解压缩即可. 第四步：把solr部署到Tomcat下。 第五步：解压缩war包。启动Tomcat解压。 第六步：把/root/solr-4.10.3/example/lib/ext目录下的所有的jar包，添加到solr工程中。 [root@localhost ext]# pwd /root/solr-4.10.3/example/lib/ext [root@localhost ext]# cp * /usr/local/solr/tomcat/webapps/solr/WEB-INF/lib/ 第七步：创建一个solrhome。/example/solr目录就是一个solrhome。复制此目录到/usr/local/solr/solrhome [root@localhost example]# pwd /root/solr-4.10.3/example [root@localhost example]# cp -r solr /usr/local/solr/solrhome [root@localhost example]# 第八步：关联solr及solrhome。需要修改solr工程的web.xml文件。 第九步：启动Tomcat访问http://192.168.25.154:8080/solr/和windows下的配置完全一样。 配置ik分词器第一步：把中文分析器添加到工程中。1、把IKAnalyzer2012FF_u1.jar添加到solr工程的lib目录下2、创建classes目录,把扩展词典、配置文件放到solr工程的WEB-INF/classes目录下。3、进入solrhome/collection1/conf中,编辑schma.xml 第二步：配置一个FieldType，制定使用IKAnalyzer修改Solr的schema.xml文件，添加FieldType： &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;/&gt; &lt;/fieldType&gt; 第三步：配置业务域，type制定使用自定义的FieldType。设置业务系统Field &lt;field name=&quot;item_title&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_sell_point&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_price&quot; type=&quot;long&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_image&quot; type=&quot;string&quot; indexed=&quot;false&quot; stored=&quot;true&quot; /&gt; &lt;field name=&quot;item_category_name&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot; /&gt; &lt;field name=&quot;item_desc&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;false&quot; /&gt; &lt;field name=&quot;item_keywords&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;false&quot; multiValued=&quot;true&quot;/&gt; &lt;copyField source=&quot;item_title&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_sell_point&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_category_name&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_desc&quot; dest=&quot;item_keywords&quot;/&gt; 第四步：重启tomcat 业务域属于开发者自定义范围内]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis学习]]></title>
      <url>%2F2016%2F04%2F14%2Fredis%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[什么是redisRedis是一个开源，高级的键值存储和一个适用的解决方案，用于构建高性能，可扩展的Web应用程序。 Redis有三个主要特点，使它优越于其它键值数据存储系统 Redis将其数据库完全保存在内存中，仅使用磁盘进行持久化，所以读写操作非常快。 与其它键值数据存储相比，Redis有一组相对丰富的数据类型。 Redis可以将数据复制到任意数量的从机中。 redis的五种数据类型./redis-cli -p 7001 -c （不加-c是连接单机版，加-c连接集群版） 字符串 Redis中的字符串是一个字节序列。Redis中的字符串是二进制安全的，这意味着它们的长度不由任何特殊的终止字符决定。因此，可以在一个字符串中存储高达512兆字节的任何内容。 [wangjian@localhost bin]$ ./redis-cli -p 7001 -c 127.0.0.1:7001&gt; set name &quot;wangke&quot; -&gt; Redirected to slot [5798] located at 192.168.25.134:7003 OK 192.168.25.134:7003&gt; get name &quot;wangke&quot; set设置一个字符值，get获得一个字符值 散列/哈希 Redis散列/哈希(Hashes)是键值对的集合。Redis散列/哈希是字符串字段和字符串值之间的映射。因此，它们用于表示对象。每个散列/哈希可以存储多达2^32 - 1个健-值对(超过40亿个)。 [wangjian@localhost bin]$ ./redis-cli -p 7001 -c 127.0.0.1:7001&gt; hset customer username &quot;wangke&quot; -&gt; Redirected to slot [6651] located at 192.168.25.134:7003 (integer) 1 192.168.25.134:7003&gt; hset customer password &quot;123&quot; (integer) 1 192.168.25.134:7003&gt; hget customer username &quot;wangke&quot; 192.168.25.134:7003&gt; hgetall customer 1) &quot;username&quot; 2) &quot;wangke&quot; 3) &quot;password&quot; 4) &quot;123&quot; hset 哈希表名 字段名 字段值 前一个哈希表类似于对象名，后面是对象的具体属性和值 hget 哈希表名 字段名 获取哈希表的字段值 hgetall 哈希表名 获取哈希表里的所有字段和属性值 列表 Redis列表只是字符串列表，按插入顺序排序。您可以向Redis列表的头部或尾部添加元素，列表的最大长度为2^32 - 1个元素(4294967295，每个列表可容纳超过40亿个元素)。 [wangjian@localhost bin]$ ./redis-cli -p 7001 -c 127.0.0.1:7001&gt; lpush list &quot;aaa&quot; -&gt; Redirected to slot [12291] located at 192.168.25.134:7005 (integer) 5 192.168.25.134:7005&gt; lpush list &quot;bbb&quot; (integer) 6 192.168.25.134:7005&gt; rpush list &quot;ccc&quot; (integer) 7 192.168.25.134:7005&gt; rpush list &quot;ddd&quot; (integer) 8 192.168.25.134:7005&gt; lpush list &quot;eee&quot; (integer) 9 192.168.25.134:7005&gt; lrang list 0 10 (error) ERR unknown command &apos;lrang&apos; 192.168.25.134:7005&gt; lrange list 0 10 1) &quot;eee&quot; 2) &quot;bbb&quot; 3) &quot;aaa&quot; 4) &quot;ccc&quot; 5) &quot;ddd&quot; lpush 列表名 值 从列表的左边添加一个值 rpush 列表名 值 从列表的右边添加一个值 lrange 列表名 起始值 结束值 获取列表起始索引位置到结束位置的值 集合Redis集合是字符串的无序集合。在Redis中，您可以添加，删除和测试成员存在的时间O(1)复杂性。一个集合中的最大成员数量为2^32 - 1(即4294967295，每个集合中元素数量可达40亿个)个。 [wangjian@localhost bin]$ ./redis-cli -p 7001 -c 127.0.0.1:7001&gt; sadd aset &quot;aaa&quot; -&gt; Redirected to slot [9458] located at 192.168.25.134:7004 (integer) 1 192.168.25.134:7004&gt; sadd aset &quot;bbb&quot; (integer) 1 192.168.25.134:7004&gt; sadd aset &quot;ccc&quot; (integer) 1 192.168.25.134:7004&gt; sadd aset &quot;ddd&quot; (integer) 1 192.168.25.134:7004&gt; sadd aset &quot;ddd&quot; (integer) 1 192.168.25.134:7004&gt; smembers aset 1) &quot;aaa&quot; 2) &quot;ddd&quot; 3) &quot;ccc&quot; 4) &quot;bbb&quot; sadd 集合名 集合值 向集合中添加一个值 smembers 集合名 获取集合中的所有值 因为集合是无序的，所以获取的值顺序和存的时候是不一样的，而且集合中元素是不重复的，所以ddd虽然添加了两次，但是获取时还是只有一个 可排序集合Redis可排序集合类似于Redis集合，是不重复的字符集合。 不同之处在于，排序集合的每个成员都与分数相关联，这个分数用于按最小分数到最大分数来排序的排序集合。虽然成员是唯一的，但分数值可以重复。 [wangjian@localhost bin]$ ./redis-cli -p 7001 -c 127.0.0.1:7001&gt; zadd sortedset 0 &quot;aaa&quot; -&gt; Redirected to slot [5990] located at 192.168.25.134:7003 (integer) 1 192.168.25.134:7003&gt; zadd sortedset 0 &quot;bbb&quot; (integer) 1 192.168.25.134:7003&gt; zadd sortedset 0 &quot;bbb&quot; (integer) 0 192.168.25.134:7003&gt; zadd sortedset 0 &quot;ccc&quot; (integer) 1 192.168.25.134:7003&gt; zadd sortedset 1 &quot;ddd&quot; (integer) 1 192.168.25.134:7003&gt; zrangebyscore sortedset 0 1000 1) &quot;aaa&quot; 2) &quot;bbb&quot; 3) &quot;ccc&quot; 4) &quot;ddd&quot; zadd 集合名 分数值 值 向可排序集合中添加一个值，并指定它的分数（分数值用于排序） zrangebyscore 集合名 分数起始值 分数结束值 按照分数值从小到大获取 可以看到可排序集合和集合特征是一样，不可重复。就是多了一点，可以通过指定分数值进行排序 java连接redis数据库进行操作 下载jar并加入到项目路径 点击 http://repo1.maven.org/maven2/redis/clients/jedis/2.1.0/jedis-2.1.0-sources.jar进行下载 下载完后将jedis.jar包加到项目classpath中 连接到redis数据库 public class TestRedis { public static void main(String[] args) { Jedis jedis = new Jedis(&quot;192.168.25.134&quot;,&quot;6379&quot;); System.out.println(jedis.ping()); } } PONG 控制台打印PONG代表连接成功 进行基本的redis操作将redis的基本操作抽成了一个工具类 public class JedisClientPool implements JedisClient { //Jedis jedis = new Jedis(&quot;192.168.25.134&quot;,&quot;6379&quot;); //与spring整合使用jedis连接池 @Autowired private JedisPool jedisPool; /** * 往redis中添加一个键值对 */ @Override public String set(String key, String value) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); String result = resource.set(key, value); resource.close(); return result; } /** * 获取redis中对应键的值 */ @Override public String get(String key) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); String result = resource.get(key); jedisPool.close(); return result; } /** * 判断redis中存在不存在这个key */ @Override public Boolean exists(String key) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); Boolean exists = resource.exists(key); resource.close(); return exists; } /** * 设置key的失效时间 */ @Override public Long expire(String key, int seconds) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); Long expire = resource.expire(key, seconds); resource.close(); return expire; } /** * 获取当前key还有多长时间失效 */ @Override public Long ttl(String key) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); Long ttl = resource.ttl(key); resource.close(); return ttl; } /** * 给指定key的值加1 */ @Override public Long incr(String key) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); Long incr = resource.incr(key); resource.close(); return incr; } /** * 往redis的哈希类型添加一个值 */ @Override public Long hset(String key, String field, String value) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); Long hset = resource.hset(key, field, value); resource.close(); return hset; } /** * 获取redis中hash类型指定key的值 */ @Override public String hget(String key, String field) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); String hget = resource.hget(key, field); resource.close(); return hget; } /** * 删除redis中hash类型中的一个key值 */ @Override public Long hdel(String key, String... field) { // TODO Auto-generated method stub Jedis resource = jedisPool.getResource(); Long hdel = resource.hdel(key, field); return hdel; } } spring整合redis在spring配置文件中加入以下配置 &lt;!-- 配置jedis单机版连接池 --&gt; &lt;bean id=&quot;jedisPool&quot; class=&quot;redis.clients.jedis.JedisPool&quot;&gt; &lt;property name=&quot;host&quot; value=&quot;192.168.25.134&quot;&gt;&lt;/property&gt; &lt;property name=&quot;port&quot; value=&quot;6379&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 如果redis是个集群的话，使用以下配置 &lt;!-- 配置jedis集群版 --&gt; &lt;bean id=&quot;jedisCluster&quot; class=&quot;redis.clients.jedis.JedisCluster&quot;&gt; &lt;constructor-arg&gt; &lt;set&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.134&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7001&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.134&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7002&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.134&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7003&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.134&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7004&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.134&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7005&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.134&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7006&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;/bean&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis集群版搭建]]></title>
      <url>%2F2016%2F04%2F12%2Fredis%E9%9B%86%E7%BE%A4%E7%89%88%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[集群搭建环境 使用ruby脚本搭建集群。需要ruby的运行环境。安装ruby yum install ruby yum install rubygems 安装ruby脚本运行使用的包。 [root@localhost ~]# gem install redis-3.0.0.gem Successfully installed redis-3.0.0 1 gem installed Installing ri documentation for redis-3.0.0... Installing RDoc documentation for redis-3.0.0... [root@localhost ~]# [root@localhost ~]# cd redis-3.0.0/src [root@localhost src]# ll *.rb -rwxrwxr-x. 1 root root 48141 Apr 1 2015 redis-trib.rb 搭建步骤需要6台redis服务器。搭建伪分布式。需要6个redis实例。需要运行在不同的端口7001-7006 第一步：创建6个redis实例，每个实例运行在不同的端口。需要修改redis.conf配置文件。配置文件中还需要把cluster-enabled yes前的注释去掉。 第二步：启动每个redis实例。第三步：使用ruby脚本搭建集群。 ./redis-trib.rb create --replicas 1 192.168.25.153:7001 192.168.25.153:7002 192.168.25.153:7003 192.168.25.153:7004 192.168.25.153:7005 192.168.25.153:7006 创建关闭集群的脚本： [root@localhost redis-cluster]# vim shutdow-all.sh redis01/redis-cli -p 7001 shutdown redis01/redis-cli -p 7002 shutdown redis01/redis-cli -p 7003 shutdown redis01/redis-cli -p 7004 shutdown redis01/redis-cli -p 7005 shutdown redis01/redis-cli -p 7006 shutdown [root@localhost redis-cluster]# chmod u+x shutdow-all.sh [root@localhost redis-cluster]# ./redis-trib.rb create --replicas 1 192.168.25.153:7001 192.168.25.153:7002 192.168.25.153:7003 192.168.25.153:7004 192.168.25.153:7005 192.168.25.153:7006 &gt;&gt;&gt; Creating cluster Connecting to node 192.168.25.153:7001: OK Connecting to node 192.168.25.153:7002: OK Connecting to node 192.168.25.153:7003: OK Connecting to node 192.168.25.153:7004: OK Connecting to node 192.168.25.153:7005: OK Connecting to node 192.168.25.153:7006: OK &gt;&gt;&gt; Performing hash slots allocation on 6 nodes... Using 3 masters: 192.168.25.153:7001 192.168.25.153:7002 192.168.25.153:7003 Adding replica 192.168.25.153:7004 to 192.168.25.153:7001 Adding replica 192.168.25.153:7005 to 192.168.25.153:7002 Adding replica 192.168.25.153:7006 to 192.168.25.153:7003 M: 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 192.168.25.153:7001 slots:0-5460 (5461 slots) master M: 8cd93a9a943b4ef851af6a03edd699a6061ace01 192.168.25.153:7002 slots:5461-10922 (5462 slots) master M: 2935007902d83f20b1253d7f43dae32aab9744e6 192.168.25.153:7003 slots:10923-16383 (5461 slots) master S: 74f9d9706f848471583929fc8bbde3c8e99e211b 192.168.25.153:7004 replicates 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 S: 42cc9e25ebb19dda92591364c1df4b3a518b795b 192.168.25.153:7005 replicates 8cd93a9a943b4ef851af6a03edd699a6061ace01 S: 8b1b11d509d29659c2831e7a9f6469c060dfcd39 192.168.25.153:7006 replicates 2935007902d83f20b1253d7f43dae32aab9744e6 Can I set the above configuration? (type &apos;yes&apos; to accept): yes &gt;&gt;&gt; Nodes configuration updated &gt;&gt;&gt; Assign a different config epoch to each node &gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join..... &gt;&gt;&gt; Performing Cluster Check (using node 192.168.25.153:7001) M: 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 192.168.25.153:7001 slots:0-5460 (5461 slots) master M: 8cd93a9a943b4ef851af6a03edd699a6061ace01 192.168.25.153:7002 slots:5461-10922 (5462 slots) master M: 2935007902d83f20b1253d7f43dae32aab9744e6 192.168.25.153:7003 slots:10923-16383 (5461 slots) master M: 74f9d9706f848471583929fc8bbde3c8e99e211b 192.168.25.153:7004 slots: (0 slots) master replicates 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 M: 42cc9e25ebb19dda92591364c1df4b3a518b795b 192.168.25.153:7005 slots: (0 slots) master replicates 8cd93a9a943b4ef851af6a03edd699a6061ace01 M: 8b1b11d509d29659c2831e7a9f6469c060dfcd39 192.168.25.153:7006 slots: (0 slots) master replicates 2935007902d83f20b1253d7f43dae32aab9744e6 [OK] All nodes agree about slots configuration. &gt;&gt;&gt; Check for open slots... &gt;&gt;&gt; Check slots coverage... [OK] All 16384 slots covered. [root@localhost redis-cluster]# 集群的使用方法Redis-cli连接集群。 [root@localhost redis-cluster]# redis01/redis-cli -p 7002 -c -c：代表连接的是redis集群]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis单机版搭建]]></title>
      <url>%2F2016%2F04%2F12%2Fredis%E5%8D%95%E6%9C%BA%E7%89%88%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[redis单机版搭建安装步骤：第一步：redis的源码包上传到linux系统。第二步：解压缩redis。第三步：编译。make第四步：安装。make install PREFIX=/usr/local/redis 1.1.连接redis1.1.1.redis的启动：前端启动： [root@localhost bin]# ./redis-server 后台启动：把/root/redis-3.0.0/redis.conf复制到/usr/local/redis/bin目录下 [root@localhost redis-3.0.0]# cp redis.conf /usr/local/redis/bin/ 修改配置文件： [root@localhost bin]# ./redis-server redis.conf查看redis进程： [root@localhost bin]# ps aux|grep redis root 5190 0.1 0.3 33936 1712 ? Ssl 18:23 0:00 ./redis-server *:6379 root 5196 0.0 0.1 4356 728 pts/0 S+ 18:24 0:00 grep redis [root@localhost bin]# 1.1.2.Redis-cli客户端使用 [root@localhost bin]# ./redis-cli 默认连接localhost运行在6379端口的redis服务。 [root@localhost bin]# ./redis-cli -h 192.168.25.153 -p 6379 -h：连接的服务器的地址-p：服务的端口号]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[zookeeper集群版搭建]]></title>
      <url>%2F2016%2F04%2F08%2Fzookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[Zookeeper集群搭建第一步：需要安装jdk环境。 第二步：把zookeeper的压缩包上传到服务器。 第三步：解压缩。 第四步：把zookeeper复制三份。 [root@localhost ~]# mkdir /usr/local/solr-cloud [root@localhost ~]# cp -r zookeeper-3.4.6 /usr/local/solr-cloud/zookeeper01 [root@localhost ~]# cp -r zookeeper-3.4.6 /usr/local/solr-cloud/zookeeper02 [root@localhost ~]# cp -r zookeeper-3.4.6 /usr/local/solr-cloud/zookeeper03 第五步：在每个zookeeper目录下创建一个data目录。 第六步：在data目录下创建一个myid文件，文件名就叫做“myid”。内容就是每个实例的id。例如1、2、3 [root@localhost data]# echo 1 &gt;&gt; myid [root@localhost data]# ll total 4 -rw-r--r--. 1 root root 2 Apr 7 18:23 myid [root@localhost data]# cat myid 1 第七步：修改配置文件。把conf目录下的zoo_sample.cfg文件改名为zoo.cfg server.1=192.168.25.154:2881:3881 server.2=192.168.25.154:2882:3882 server.3=192.168.25.154:2883:3883 第八步：启动每个zookeeper实例。启动bin/zkServer.sh start 查看zookeeper的状态：bin/zkServer.sh status]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[nginx负载均衡服务器搭建]]></title>
      <url>%2F2016%2F04%2F07%2Fnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[nginx安装 官网下载nginx 安装相关依赖 yum install gcc-c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 解压缩nginx的安装包 使用configure命令创建一makeFile文件。 ./configure \ --prefix=/usr/local/nginx \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --with-http_gzip_static_module \ --http-client-body-temp-path=/var/temp/nginx/client \ --http-proxy-temp-path=/var/temp/nginx/proxy \ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ --http-scgi-temp-path=/var/temp/nginx/scgi 创建nginx运行所需目录 mkdir -p /var/temp/nginx/ make make install 启动nginx进入sbin目录 [root@localhost sbin]# ./nginx 关闭nginx： [root@localhost sbin]# ./nginx -s stop 推荐使用： [root@localhost sbin]# ./nginx -s quit 重启nginx：1、先关闭后启动。2、刷新配置文件： [root@localhost sbin]# ./nginx -s reload 配置虚拟主机通过端口区分Nginx的配置文件：/usr/local/nginx/conf/nginx.conf #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { #一个server节点就是一个虚拟主机 listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; #html是nginx安装目录下的html目录 index index.html index.htm; } } } 可以配置多个server，配置了多个虚拟主机。添加虚拟主机： #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } } server { listen 81; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-81; index index.html index.htm; } } } 重新加载配置文件 [root@localhost nginx]# sbin/nginx -s reload 通过域名区分 #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } } server { listen 81; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-81; index index.html index.htm; } } server { listen 80; server_name www.taobao.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-taobao; index index.html index.htm; } } server { listen 80; server_name www.baidu.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-baidu; index index.html index.htm; } } } 配置反向代理服务器第一步：安装两个tomcat，分别运行在8080和8081端口。第二步：启动两个tomcat。第三步：反向代理服务器的配置 upstream tomcat1 { server 192.168.25.148:8080; } server { listen 80; server_name www.sina.com.cn; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://tomcat1; index index.html index.htm; } } upstream tomcat2 { server 192.168.25.148:8081; } server { listen 80; server_name www.sohu.com; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://tomcat2; index index.html index.htm; } } 第四步：nginx重新加载配置文件 第五步：配置域名在hosts文件中添加域名和ip的映射关系192.168.25.148 www.sina.com.cn192.168.25.148 www.sohu.com 配置负载均衡在hosts文件中添加多个相同域名的服务器 upstream tomcat2 { server 192.168.25.148:8081; server 192.168.25.148:8082; } 为多个服务器分配权重 upstream tomcat2 { server 192.168.25.148:8081 weifht=3;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux学习]]></title>
      <url>%2F2016%2F04%2F06%2Flinux%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[linux目录/： 根目录， 一般根目录下只存放目录， 在Linux下有且只有一个根目录。 所有的东西 都是从这里开始。 当你在终端里输入“/home”， 你其实是在告诉电脑， 先从/（ 根目 录） 开始， 再进入到home目录。 /bin、 /usr/bin: 可执行二进制文件的目录， 如常用的命令ls、 tar、 mv、 cat等。 /boot： 放置linux系统启动时用到的一些文件， 如Linux的内核文件： /boot/vmlinuz,系统引导管理器： /boot/grub。 /dev： 存放linux系统下的设备文件， 访问该目录下某个文件， 相当于访问某个设备， 常见的是挂载光驱 mount /dev/cdrom /mnt。 /etc： 系统配置文件存放的目录， 不建议在此目录下存放可执行文件， 重要的配置文 件有 /etc/inittab、 /etc/fstab、 /etc/init.d、 /etc/X11、 /etc/sysconfig、 /etc/xinetd.d。 /home： 系统默认的用户家目录， 新增用户账号时， 用户的家目录都存放在此目录 下， ~表示当前用户的家目录， ~edu 表示用户 edu 的家目录。 /lib、 /usr/lib、 /usr/local/lib： 系统使用的函数库的目录， 程序在执行过程中， 需要调 用一些额外的参数时需要函数库的协助。 /lost+fount： 系统异常产生错误时， 会将一些遗失的片段放置于此目录下。 /mnt: /media： 光盘默认挂载点， 通常光盘挂载于 /mnt/cdrom 下， 也不一定， 可以选 择任意位置进⾏挂载。 /opt： 给主机额外安装软件所摆放的目录。 /proc： 此目录的数据都在内存中， 如系统核心， 外部设备， 网络状态， 由于数据都存 放于内存中， 所以不占用磁盘空间， 比较重要的目录有 /proc/cpuinfo、 /proc/interrupts、 /proc/dma、 /proc/ioports、 /proc/net/* 等。 /root： 系统管理员root的家目录。 /sbin、 /usr/sbin、 /usr/local/sbin： 放置系统管理员使用的可执行命令， 如fdisk、 shutdown、 mount 等。 与 /bin 不同的是， 这几个目录是给系统管理员 root使用的命 令， 一般用户只能&quot;查看&quot;而不能设置和使用。 /tmp： 一般用户或正在执行的程序临时存放文件的目录， 任何人都可以访问， 重要数 据不可放置在此目录下。 /srv： 服务启动之后需要访问的数据目录， 如 www 服务需要访问的网页数据存放在 /srv/www 内。 /usr： 应用程序存放目录， /usr/bin 存放应用程序， /usr/share 存放共享数据， /usr/lib 存放不能直接运行的， 却是许多程序运行所必需的一些函数库文件。 /usr/local: 存放 软件升级包。 /usr/share/doc: 系统说明文件存放目录。 /usr/share/man: 程序说明文件 存放目录。 /var： 放置系统执行过程中经常变化的文件， 如随时更改的日志文件 /var/log， /var/log/message： 所有的登录文件存放目录， /var/spool/mail： 邮件存放 的目录， /var/run:程序或服务启动后， 其PID存放在该目录下。 liunx常用指令man命令使用man命令查询帮助文档时,可以使用以下快捷键f 向前翻一页b 向后翻一页(和空格键一样的效果)Enter键 向下滚动一行/word 在文档中搜索word字符串 ls命令ls 查看文件命令,类似于dos的dir命令. 代表当前目录 ..代表上一级目录-a 显示指定目录下所有子目录与文件,包括隐藏目录-l 以列表方式显示文件的详细信息-h 配合-l以人性化的方式显示文件大小(直接使用-h没啥效果) 文件属性含义 1 2 3 4 5 6 7 -rw-r--r-- 1 root root 14 11月 24 01:31 file3 1: 第一个字符代表文件的类型,后面9位是文件的权限,前三位是文件创建用户的权限,中间三位是文件创建用户所属组的权限,后面三位是其他用户的权限.2: 文件的硬链接数3: 文件的创建用户,拥有者4: 文件创建用户所属的组5: 文件的大小6: 文件的创建时间7: 文件名 linux命令中通配符的使用可以使用* 来匹配多个文件 代表文件名中的所有字符ls te 查找文件名以te开头的文件ls html 查找文件名以html结尾的文件? 代表文件名中任意一个字符ls ?.c 查找文件名第一个字符任意,后缀为.c的文件ls a.? 查找文件名最后一个字符任意,前面是a.的文件[] [和]将字符组括起来,表示可以匹配字符组中的任意一个,-用于表示字符范围[abc] 匹配abc中的任意一个[a-f] 匹配从a到f范围内的任意一个字符ls [a-f] 查找文件名以a到f中任意一个字符开头的文件ls a-f 查找文件名为a-f的文件,当-处于方括号之外,失去通配符的作用\ 如果要使通配符作为普通字符使用,可以在其前面加上转义字符.?和处于方括号内时不用使用转义字符就失去通配符的作用 输出重定向.&gt;输出重定向命令可以将本应该显示到终端的内容输出到文件中ls &gt; test.txt(如果该文件不存在就会自动创建)打开该文件就可以看到本应该显示在终端上的内容 cat命令cat 可以查看文件内容当内容过多时,会出现文件内容在屏幕上快速滚动这时可以使用more 命令进行分屏显示more命令展示的内容 可以使用man命令下的那些快捷键协助查看 |管道符| 管道符一个命令的输出可以当作另一个命令的输入如果目录下子文件和目录比较多的话,就可以用下面这个命令,将ls -lh的命令结果在页面上分屏显示ls -lh | more clearclear命令清空屏幕,和dos的cls命令效果一样.假清屏,之前的内容还在上方,还可以使用ctrl+l快捷键. cdcd命令切换工作目录cd后面可以跟绝对路径,也可以跟相对路径cd 如果后面不跟任何目录,则会切换到当前用户的主目录(就是家目录,/home/用户目录),用户刚登录的时候,默认就在用户目录下cd ~ 切换到当前用户的主目录cd . 切换到当前目录cd .. 切换到上级目录cd - 可进入上次所在的目录,和windows的后退一样 pwdpwd 显示当前所在目录 mkdirmkdir 创建目录后面接要创建的目录名 mkdir test接-p参数可以递归创建目录 mkdir a/b/c -p值得注意的是,新建的目录不能和当前已经存在的目录或者文件重名,并且目录创建者在当前目录拥有写的权限 treetree命令 ,可以用树状图的形式显示指定目录下的目录结构 rmdirrmdir 删除目录需要注意:删除目录之前,目录得是空目录,目录下没有任何文件和目录,并且不能处于该目录下,要离开该目录,而且删除该目录的用户对该目录需要拥有写的权限 rmrm 删除文件或者目录参数:-i 以进行交互的方式执行,删除前会询问是否删除-f 强制删除,忽略不存在的文件,不会询问-r 递归的删除目录下的文件,删除文件夹的时候必须加上此参数 lnln 建立链接文件链接文件类似与windos的快捷方式分为硬链接和软链接区别就是删除源文件的时候,软链接会失效,无法使用,而硬链接可以继续使用,没有影响(删除源文件,软硬链接文件还会存在)ln 源文件 链接文件 –&gt; 建立一个硬链接ln -s 源文件 链接文件 –&gt; 建立一个软链接注意:如果软链接文件和源文件不在同一个目录下,源文件要使用绝对路径,不能使用相对路径 catcat命令除了可以显示文件内容外,还可以通过输出重定向将两个文件内容合并到一个文件中cat 文件1 文件2 &gt; 文件3 将文件1和文件2的内容合并到文件3中.&gt;代表将内容输出到文件3中,但是会将文件3中原有的内容覆盖掉,如果想保留文件3的内容,只是将合并内容追加到原有内容后面,则可以使用 &gt;&gt; 两个&gt;代表追加 grepgrep 文本搜索grep [-选项] ‘搜索内容串’ 文件名-v 显示不包含匹配文本的所有行(相当于求反)-n 显示匹配行及行号-i 忽略大小写grep搜索内容串可以是正则表达式grep常用正则表达式^a 行首,搜索以a开头的行;grep -n ‘^a’ 1.txtke$ 行尾,搜索以ke结束的行;grep -n ‘ke$’ 1.txt[Ss]igna[Ll] 匹配[]里中字符组中的其中一个字符. 点匹配任意一个字符,除了换行符,和上面通配符的?效果一样 findfind 文件查找用来在特定的目录下搜索符合条件的文件,也可以用来搜索特定用户属主的文件find ./ -name test.sh 查找当前目录下所有名为tesh.sh的文件 后面的文件名可以使用通配符,不过需要用单或双引号引起来find ./ -name ‘.sh’ 查找当前目录下所有名以.sh结尾的文件find ./ -name ‘[A-Z]‘ 查找当前目录下所有名以A到Z中的一个字符开头的文件 find 后面还可以加参数 查找满足某些条件的文件find /tmp -size 2M 查找/tmp目录下文件大小为2M的文件find /tmp -size +2M 查找/tmp目录下文件大小大于2M的文件find /tmp -size -2M 查找/tmp目录下文件大小小于2M的文件find ./ -size +4K -size -5M 查找当前目录下文件大小大于4k小于5M的文件find ./ -perm 0777 查找当前目录下权限为777的文件或者目录 cpcp 拷贝文件将给出的文件或者目录复制到另一个文件或目录中,相当于DOS下的copy命令常用选项参数-a 该选项通常在复制目录时使用,它保留链接,文件属性,并递归地复制目录,简单而言,保持文件原有属性-f 禁止交互式操作,如有覆盖也不会给出提示,相当于强制执行-i 交互式复制,在覆盖目标文件之前将给出提示要求用户确认-r 若给出的源文件是目录文件,则会递归复制该目录下的所有子目录和文件,目标文件必须为一个目录名-v 显示拷贝进度 mvmv移动文件 相当于windows的剪切mv命令除了可以移动文件或目录,还可以给文件或目录重命名常用选项参数-f 禁止交互式操作,如有覆盖也不会给出提示,相当于强制执行-i 交互式移动,如果移动的目录已经有同名文件,会给出提示要求用户确认是否覆盖-v 显示移动进度 tartar 归档管理,打包和解包计算机中的数据经常需要备份,tar是Unix和Linux中最常用的备份工具,此命令可以把一系列文件归档到一个大文件中,也可以把档案文件解开以恢复数据,tar使用格式tar [参数] 打包文件名 文件1,文件2,文件3tar命令很特殊,其参数前面可以不加-常用选项参数-c 生成档案文件,创建打包文件-v 列出归档解档的详细过程,显示进度-f 指定档案文件名称,f后面一定是.tar文件,所以必须放选项最后-t 列出档案中包含的文件-x 解开档案的文件注意:除了f需要放在参数的最后,其他参数的顺序任意 gzipgzip 文件压缩解压tar与gzip命令结合使用实现文件打包,压缩.tar只负责打包文件,但不压缩,用gzip压缩tar打包后的文件,其扩展名一般用xxx.tar.gzgzip使用格式如下gzip [选项] 被压缩文件 [压缩后的文件名] 不写压缩后的文件名默认是在压缩的文件名后加上.gz常用选项参数-d 解压-r 压缩所有子目录gzip -r test.tar test.tar.gz 等同于 gzip -r test.targzip -d test.tar.gz tar这个命令并没有压缩的功能,它只是一个打包的命令,但是在tar命令中增加一个选项(-z)可以调用gzip实现了一个压缩的功能,执行一个先打包后压缩的过程压缩用法: tar zcvf 压缩包包名 文件1,文件2tar cvzf test.tar.gz ./* 将当前目录下的所有文件打包压缩到test.tar.gz文件中 解压用法: tar zxvf 压缩包包名tar zxvf test.tar.gz解压时还可以加上一个参数 -C 将文件解压到指定目录tar zxvf test.tar.gz -C ./test 将文件解压到当前目录下的test文件夹中 bzip2bzip2 文件压缩解压bzip2是另一种压缩方式,用法和gzip一样,也可以结合tar命令使用,只用在tar命令中加一个选项参数-j,就可以实现用bzip2对文件进行压缩和解压操作压缩用法 tar -jcvf 压缩包包名 文件1,文件2,文件3解压用法 tar -jxvf 压缩包包名bzip2压缩的文件文件名一般为xxx.tar.bz2 zip,uzipzip,unzip 文件压缩解压通过zip压缩文件的目标文件不需要指定扩展名,默认扩展名为zip压缩文件: zip [r] 目标文件 源文件解压文件 unzip -d 解压后目录文件 压缩文件zip myzip * 将当前目录下的所有文件和目录压缩到myzip中unzip -d /test myzip.zip 将myzip解压到当前目录下的test文件夹下需要注意:当被压缩的文件中有失效的软链接,这个软链接并不会被加到压缩文件里 whichwhich 查看命令位置which ls 查看ls命令所在位置当输入了一个不存在的命令,将什么都不返回 whoamiwhoami 查看当前用户用该命令可以查看当前系统当前帐号的用户名,可通过cat /etc/passwd查看系统用户信息 whowho 查看登录用户用于查看当前所有登录系统的用户信息常用选项参数:-m或am I 只显示运行who命令的用户用户名,登录终端和登录时间(默认选项)-q或–count 只显示用户的登录帐号和登录用户的数量-u或–heading 显示列标题 exitexit 退出登录账户如果是图形界面,退出当前终端如果是使用ssh远程登录,退出登录账户如果是切换后的登陆用户,退出则返回上一个登陆帐号 useradduseradd 添加用户帐号在unix/linux中添加用户帐号可以使用adduser或useradd,因为adduser命令是指向useradd命令的一个链接,因此,这两个命令的使用格式完全一样使用格式: useradd [参数] 新建用户帐号常用参数选项:-d 指定用户登录系统时的主目录,如果不是该参数,系统自动在/home目录下建立与用户名同名的目录为主目录-m 自动建立目录-g 指定组名称相关说明:linux每个用户都要有一个主目录,主目录就是第一次登录系统,用户的默认当前目录(/home/用户名)每一个用户必须有一个主目录,所以用useradd创建用户的时候,一定给用户指定一个主目录用户的主目录一般要放到根目录的home目录下,用户的主目录和用户名是相同的如果创建用户的时候,不指定组名,那么系统会自动创建一个和用户名一样的组名用法useradd -d /home/abc abc -m 创建abc用户,如果/home/abc目录不存在,就自动创建这个目录,同时用户属于abc组useradd -d /home.a a -g test -m创建一个用户名字叫a,主目录在/home/a,如果主目录不存在,就自动创建主目录,同时用户属于test组cat /etc/passwd 查看当前用户的信息 passwdpasswd 设置用户密码早Unix/Linux中,超级用户可以使用passwd命令为普通用户设置或修改用户口令.用户也可以直接使用该命令来修改自己的口令,而无需在命令后面使用用户名 userdeluserdel 删除用户用法:userdel abc 删除abc用户,但不会自动删除用户的主目录userdel -r abc 删除abc用户,同时删除用户的主目录(用户名相同的组也删除了) susu 切换用户用法:su abc 切换到abc用户,键入命令后输入abc用户的密码即可以切换到abc用户直接使用su 用户名,切换用户后并不会进去到该用户的主目录,可以在su命令后加个- su - 用户名 这样切换用户之后直接就在该用户的主目录下注意:在ubuntu下,执行命令前需要加sudo sudo su root在ubuntu下,一些需要root才能操作的命令,可以直接在命令前加sudo执行,这样就免去了要切换到管理员的麻烦 sudo -s 切换到超级管理员的一个简单用法 查看有哪些用户组方法一:cat /etc/group方法二:groupmod + 三次tab键 groupadd groupdelgroupadd 添加组帐号 groupdel 删除组帐号用法:groupadd 组名groupdel 组名执行groupadd和groupdel命令需要超级管理员权限,可以切换到超级管理员sudo -s 或者在命令前加上sudo执行 usermodusermod 修改用户所在组用法:usermod -g 用户组 用户名注意:-g添加的组属于用户的默认组,用户所创建的文件显示的组就是默认组 -G一般与 -a 使用,用于追加组 groupsgroups 查看用户在哪些组用法:groups 用户名 为创建的普通用户添加sudo权限新创建的用户,默认不能sudo,需要进行以下两步操作sudo usermod -a -G adm 用户名sudo usermod -a -G sudo 用户名 usermod -g 和 -G的区别-g 用来制定这个用户默认的用户组-G 一般配合’-a’来完成向其他组添加 chmodchmod 修改文件权限chmod修改文件权限有两种使用格式:字母法与数字法字母法:chmod u/g/o/a +/-/= rwx 文件u user,代表文件的所有者g group,表示与该文件的所有者属于同一组者,即用户组o other,表示其他人a all,表示这三者都是 增加权限 撤销权限= 设定权限r read,表示可读取,对于一个目录,如果没有r权限,那么就意味着不能通过ls查看这个目录的内容w write,表示可写入,对于一个目录,如果没有w权限,那么就意味着不能在目录下创建新的文件.x excute,表示可执行,对于一个目录,如果没有x权限,那么就以为这不能通过cd进入这个目录 用法:chmod u+x test 给用户添加test目录的执行权限chmod g-r test 给同组的用户撤销test目录的可读权限chmod u+x,g-r,u+r test 给用户,同组其他人分别进行权限操作chmod a+x test 给用户,同组其他人都加上test目录的可执行权限 数字法:“rwx”这些权限也可以用数字来代替r 读取权限,数字代号为”4”w 读取权限,数字代号为”2”x 执行权限,数字代号为”1” 不具任何权限,数字代号为”0” 用法与上面相同,就是rwx换成相应的数字可以直接使用chmod 777 test 为test目录修改权限,直接使用数字,三个数字分别按顺序代表ugo,不需要显示声明 如果想递归所有目录加上相同权限,需要加上参数 -Rchmod 777 test/ -R test目录下的所有子文件和目录都是777权限 chownchown 修改文件所有者用法:chown 用户名 文件名 需要超级管理员权限 chgrpchgrp 修改文件所属组用法:chgrp 用户组 文件名 需要超级管理员权限 calcal 查看当前日历cal命令用于查看当月日历,-y显示整年日历 datedate 显示或者设置时间设置时间用法:date [MMDDhhmm[[CC]YY]][.ss] + formatCC为年前两位,YY为年的后两位,MM为月,DD为天,hh为小时,mm为分钟,ss为秒如2016年1月2号3点四分55秒写成date 010203042016.55 显示时间格式(date ‘+%y,%m,%d,%H,%M,%S’)显示年月日date ‘+%Y-%m-%d’ psps 查看进程信息进程是一个具有一定独立功能的程序.它是操作系统动态执行的基本单元.ps命令可以查看进程的详细状况常用选项参数:-a 显示终端上的所有进程,包括其他用户的进程-u 显示进程的详细状态-x 显示没有控制终端的进程-w 显示加宽,以便显示更多的信息-r 只显示正在运行的进程一般常用 ps -aux toptop 动态显示进程用来动态显示运行中的进程.top命令能够在运行后,在指定的时间间隔更新显示信息.可以在使用top命令时加上-d来指定显示信息更新的时间间隔.在top命令执行后,可以按以下按键对显示的结果进行排序M 根据内存使用量来排序P 根据CPU占有率来排序T 根据进程运行时间的长短来排序U 可以根据后面输入的用户名来筛选进程K 可以根据后面输入的PID来杀死进程q 退出h 获得帮助 killkill 终止进程kill命令指定进程号的进程,需要配合ps使用.使用方法:kill [-signal] pid信号值从0到15,其中9为绝对终止,可以处理一般信号无法终止的进程 reboot,shutdown,init 关机重启使用方法:reboot 重新启动操作系统shutdown -r now 重新启动操作系统,shutdown会给其他用户提示shutdown -h now 立刻关机,其中now相当于时间为0的状态shutdown -h 20:25 系统在今天的20:25会关机shutdown -h +10 系统再过十分钟后自动关机init 0 关机init 6 重启 df 检测磁盘空间df命令用于检测文件系统的磁盘空间占用和空余情况,可以显示所有文件系统对节点和磁盘块的使用情况常用选项参数:-a 显示所有文件系统的磁盘使用情况-m 以1024字节为单位显示-t 显示各指定文件系统的磁盘空间使用情况-T 显示文件系统 du 检测目录所占磁盘空间du命令用于统计目录或文件所占磁盘空间的大小,该命令的执行结果与df类似,du更侧重于磁盘的使用状况使用方式 du [选项] 目录或文件名常用选项参数:-a 递归显示指定目录中各文件和子目录中文件占用的数据块-s 显示指定文件或目录占用的数据块-b 以字节为单位显示磁盘占用情况-l 计算所有文件大小,对硬链接文件计算多次 ifconfig 查看或配置网卡信息如果,我们只是敲:ifconfig 它会显示所有网卡的信息.通过超级管理员权限,可以修改网卡的信息如: sudo ifconfig 网卡名 ip地址 可以将指定网卡的ip地址修改为设置的 pingping 测试远程主机连通性用法:ping ip地址/域名]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[activiti工作流学习]]></title>
      <url>%2F2016%2F03%2F18%2Factiviti%E5%B7%A5%E4%BD%9C%E6%B5%81%2F</url>
      <content type="text"><![CDATA[什么是activitiactiviti是一款业务流程管理框架，用于处理企业业务处理在计算机应用环境下的自动化 activiti需要了解的工作流框架底层是有一套数据库提供支持的，针对不同的数据库提供不同的sql建表语。 Activiti5.13框架对应23张表，JBPM4.4框架对应18张表。开发人员不需要自己编写sql操作这些表的，框架底层会生成sql操作。Activiti框架底层使用mybatis操作数据库 数据表：Activiti的后台是有数据库的支持，所有的表都以ACT_开头。第二部分是表示表的用途的两个字母标识。 用途也和服务的API对应。 ACTRE\*: ‘RE’表示repository。 这个前缀的表包含了流程定义和流程静态资源 （图片，规则，等等）。 ACTRU\*: ‘RU’表示runtime。 这些运行时的表，包含流程实例，任务，变量，异步任务，等运行中的数据。 Activiti只在流程实例执行过程中保存这些数据， 在流程结束时就会删除这些记录。 这样运行时表可以一直很小速度很快。 ACTID\*: ‘ID’表示identity。 这些表包含身份信息，比如用户，组等等。 ACTHI\*: ‘HI’表示history。 这些表包含历史数据，比如历史流程实例， 变量，任务等等。 ACTGE\*: 通用数据， 用于不同场景下。 总结activiti中的几个对象:工作流引擎processEngine负责生成流程、及流程运行时各种实例及数据的监控与管理 几个和流程相关的对象 Deployment:部署对象，和部署表对应act_re_deployment ProcessDefinition:流程定义对象,和流程定义表对应act_re_procdef ProcessInstance:流程实例对象,和流程实例表对应act_ru_execution Task:任务对象,和任务表对应act_ru_task 几个Service对象 RepositoryService:操作部署、流程定义等静态资源信息 RuntimeService:操作流程实例，启动流程实例、查询流程实例、删除流程实例等动态信息 TaskService:操作任务，查询任务、办理任务等和任务相关的信息 HistoryService:操作历史信息的，查询历史信息 IdentityService:操作用户和组 几个Query对象 DeploymentQuery:对应查询部署表act_re_deployment ProcessDefinitionQuery:对应查询流程定义表act_re_procdef ProcessInstanceQuery:对应查询流程实例表act_ru_execution TaskQuery:对应查询任务表act_ru_task activiti表的生成在spring配置文件中加上下面这些配置 &lt;!-- 配置一个流程引擎配置对象 --&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&gt; &lt;property name=&quot;jdbcDriver&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql:///activiti&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcUsername&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcPassword&quot; value=&quot;xxx&quot;&gt;&lt;/property&gt; &lt;!--当数据库没有表时，创建表 --&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置一个流程引擎工厂bean，用于创建流程引擎对象 --&gt; &lt;bean id=&quot;processEngine&quot; class=&quot;org.activiti.spring.ProcessEngineFactoryBean&quot;&gt; &lt;property name=&quot;processEngineConfiguration&quot; ref=&quot;processEngineConfiguration&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 然后运行下面java代码，即可生成activiti的23张表 /** * 获取流程定义对象 */ public class ProcessEngineUtils { private ProcessEngineUtils(){} public static ProcessEngine getProcessEngine(){ ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti-context.xml&quot;, &quot;processEngineConfiguration&quot;); ProcessEngine processEngine = configuration.buildProcessEngine(); return processEngine; } } 当配置文件名称为actiitiv-context.xml或者activiti.cfg.xml,并且配置文件放在项目根路径下。配置文件中必须配置流程引擎配置对象和流程引擎工程bean，并且id分别得为processEngineConfiguration和processEngine,这样代码就可以简化为 /** * 获取流程定义对象 */ public class ProcessEngineUtils { private ProcessEngineUtils(){} public static ProcessEngine getProcessEngine(){ ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); ProcessEngine processEngine = (ProcessEngine) context.getBean(&quot;processEngine&quot;); return processEngine; } } activiti的基本操作使用上面的工具类获取流程引擎对象 public class TestActivitiOperate { private ProcessEngine processEngine = ProcessEngineUtils.getProcessEngine(); /** * 测试是否能获取到processEngine对象 */ @Test public void testGenerateProcessEngine() { ProcessEngine processEngine = ProcessEngineUtils.getProcessEngine(); System.out.println(processEngine); } /** * 部署流程定义 * 影响了如下几张表 * act_ge_bytearray : 存储两个资源文件,bpmn和png * act_re_deployment : 部署对象的属性 * act_re_procdef : 流程定义对象,部署了一个流程,相应的就 * 生成了一个流程定义对象 */ @Test public void deploymentProcess() { //获取流程引擎对象 ProcessEngine processEngine = ProcessEngineUtils.getProcessEngine(); //获取流程发布对象,通过仓库service获取 DeploymentBuilder deployment = processEngine.getRepositoryService().createDeployment(); //添加bpmn和png资源 deployment.addClasspathResource(&quot;process/test.bpmn&quot;); deployment.addClasspathResource(&quot;process/test.png&quot;); //部署,返回部署对象 Deployment deploy = deployment.deploy(); //打印部署对象id System.out.println(deploy.getId()); } /** * 查询流程定义 */ @Test public void queryProcessDef() { //创建一个流程定义查询对象 ProcessDefinitionQuery processDefinitionQuery = ProcessEngineUtils.getProcessEngine().getRepositoryService().createProcessDefinitionQuery(); //设置过滤条件,根据流程定义的key值 processDefinitionQuery.processDefinitionKey(&quot;bxlc&quot;); //设置排序条件 processDefinitionQuery.orderByProcessDefinitionVersion().desc(); //查询 List&lt;ProcessDefinition&gt; list = processDefinitionQuery.list(); //遍历 for (ProcessDefinition processDefinition : list) { System.out.println(processDefinition.getId() + &quot; &quot; + processDefinition.getName() + &quot; &quot; + processDefinition.getVersion()); } } /** * 启动流程实例 * 影响了如下几张表: * act_ru_execution : 记录当前运行的流程 * act_ru_task : 记录当前运行的任务 */ @Test public void startProcess() { //声明一个流程定义id String processDefinitionId = &quot;bxlc:1:4&quot;; //通过运行时service启动一个流程实例 ProcessInstance processInstance = ProcessEngineUtils.getProcessEngine().getRuntimeService().startProcessInstanceById(processDefinitionId); //打印一下流程实例的id System.out.println(processInstance.getId()); } /** * 查询任务 */ @Test public void queryTask() { //根据任务Service对象创建一个任务查询对象 TaskQuery taskQuery = ProcessEngineUtils.getProcessEngine().getTaskService().createTaskQuery(); //根据任务的办理人过滤 taskQuery.taskAssignee(&quot;张三&quot;); List&lt;Task&gt; list = taskQuery.list(); for (Task task : list) { System.out.println(task.getId() + &quot; &quot; + task.getName() + &quot; &quot; + task.getAssignee()); } } /** * 办理任务 * 办理完成 act_ru_task表会更新下一个任务,流程完成表会清空 */ @Test public void completeTask() { String taskId = &quot;2104&quot;; //根据taskService完成任务 processEngine.getTaskService().complete(taskId); } /** * 设置流程变量,启动流程实例时设置 */ @Test public void setVariableOnStart() { //定义一个流程声明id String processDefinitionId = &quot;qjlc:3:304&quot;; //定义一个map,存储流程变量 Map&lt;String, Object&gt; variable = new HashMap&lt;&gt;(); variable.put(&quot;key1&quot;, &quot;value1&quot;); variable.put(&quot;key2&quot;, &quot;value2&quot;); //启动一个流程实例,并传入流程变量 ProcessInstance processInstance = processEngine.getRuntimeService().startProcessInstanceById(processDefinitionId, variable); //打印一下流程实例的id System.out.println(processInstance.getId()); } /** * 办理任务时设置流程变量 */ @Test public void setVariableOnTask() { String taskId = &quot;1006&quot;; Map&lt;String, Object&gt; variable = new HashMap&lt;&gt;(); variable.put(&quot;k1&quot;, &quot;v1&quot;); variable.put(&quot;k2&quot;, &quot;v2&quot;); processEngine.getTaskService().complete(taskId, variable); } /** * 通过RuntimeService设置流程变量 */ @Test public void setVariableByRuntimeServie() { String processInstanceId = &quot;1001&quot;; //设置单个变量,分别定义键和值,然后传入 String key = &quot;mmm&quot;; String value = &quot;qqq&quot;; processEngine.getRuntimeService().setVariable(processInstanceId, key, value); //设置多个变量 Map&lt;String, Object&gt; variable = new HashMap&lt;&gt;(); variable.put(&quot;rs1&quot;, &quot;aaa&quot;); variable.put(&quot;rs2&quot;, &quot;bbb&quot;); processEngine.getRuntimeService().setVariables(processInstanceId, variable); } /** * 通过taskService设置任务变量 */ @Test public void setVariableByTaskService() { //任务id String taskId = &quot;1104&quot;; //设置单个键值对 String key = &quot;ts1&quot;; String value = &quot;aaa&quot;; processEngine.getTaskService().setVariable(taskId, key, value); //设置多个变量 Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;ts2&quot;, &quot;bbb&quot;); map.put(&quot;ts3&quot;, &quot;ccc&quot;); processEngine.getTaskService().setVariables(taskId, map); } /** * 通过RuntimeService获取流程变量 */ @Test public void getVariableByRuntimeService() { //获取单个变量 String processId = &quot;1001&quot;; String key = &quot;rs1&quot;; Object value = processEngine.getRuntimeService().getVariable(processId, key); System.out.println(value); //获取多个变量 Map&lt;String, Object&gt; variables = processEngine.getRuntimeService().getVariables(processId); for (String s : variables.keySet()) { Object o = variables.get(s); System.out.println(s + &quot; &quot; + o.toString()); } } /** * 通过TaskService获取流程变量 */ @Test public void getVariableByTaskService() { //设置任务id String taskId = &quot;1104&quot;; //设置键,获取值 String key = &quot;ts1&quot;; Object variable = processEngine.getTaskService().getVariable(taskId, key); System.out.println(variable); //获取多个变量 Map&lt;String, Object&gt; variables = processEngine.getTaskService().getVariables(taskId); System.out.println(variables); } /** * 创建组 */ @Test public void createGroup() { //创建一个组 Group group = new GroupEntity(); //为组设置id和name group.setId(&quot;经理&quot;); group.setName(&quot;经理&quot;); //保存组 processEngine.getIdentityService().saveGroup(group); } /** * 创建用户 */ @Test public void createUser() { User user = new UserEntity(); user.setId(&quot;003&quot;); user.setFirstName(&quot;李四&quot;); User user1 = new UserEntity(); user1.setId(&quot;005&quot;); user1.setFirstName(&quot;王五&quot;); processEngine.getIdentityService().saveUser(user); processEngine.getIdentityService().saveUser(user1); } /** * 将用户加入组中 */ @Test public void putUserToGroup() { String userId1 = &quot;003&quot;; String userId2 = &quot;005&quot;; String groupId = &quot;经理&quot;; processEngine.getIdentityService().createMembership(userId1, groupId); processEngine.getIdentityService().createMembership(userId2, groupId); } /** * 查询组任务 */ @Test public void queryGroupTask() { TaskQuery taskQuery = processEngine.getTaskService().createTaskQuery(); // 根据用户组查询组任务 taskQuery.taskCandidateGroup(&quot;经理&quot;); //根据用户查询组任务(查询没有结果,因为我的用户是通过代码加到组里的,和直接设置CandidateUser还是有区别的) //taskQuery.taskCandidateUser(&quot;李四&quot;); List&lt;Task&gt; list = taskQuery.list(); for (Task task : list) { System.out.println(task.getId() + &quot; &quot; + task.getName()); } } /** * 完成组任务 */ @Test public void completeGroupTask(){ String taskId = &quot;2202&quot;; processEngine.getTaskService().complete(taskId); } }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[intellij下activiti designer插件安装及使用]]></title>
      <url>%2F2016%2F03%2F18%2Fintellij%E4%B8%8Bactiviti%20designer%E6%8F%92%E4%BB%B6%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[intellij idea下activiti designer插件安装我的intellij版本为2016.1.1. 点击上方工具栏file–&gt;setting打开设置界面,或者使用ctrl+alt+s快捷键打开,然后点击Plugins,进去插件页面. intellij下的activiti designer插件名为actiBPM.如下图,在搜索框输入名称. 然后点击红线处,进入下图界面,点击install进行下载 下载完成之后重启intellij,actiBMP插件就安装成功了 actiBPM插件使用插件安装完成之后,在项目目录右键,点击new,就会看到文件列表中出现了一个BPMN file文件,点击即可新建一个bpmn文件 不过我的这个intellij版本新建会有一个小bug,如下图 输入名称之后,点击ok,并没有任何反应,但是其实文件已经新建成功,点击X或者Cancel即可以看到目录下生成了一个a.bpmn文件 点击文件即可进入画图面板,可以进行流程设计了 右边选择图标,左边填写信息 根据bpmn文件生成png文件在eclipse下的activiti designer插件可以在设置里设置保存bmpn文件即生成png文件.但是intellij却没有这功能,虽然在插件页面,actiBPM作者说了一个方法,但是并没有啥用 百度了好久,学会了一个生成png图片的方法,虽然比较麻烦 在新建的文件上右键,选择Refactor–&gt;Rename,或者直接alt+shift+r快捷键打开重命名界面,将后缀名改为xml 然后再右键刚改完名的文件,在下方点击Diagrams 选择第一个Show BPMN 2.0 Diagrams后即可打开图片界面,点击下方的红线处,选择目录,填写好文件名,点击ok,即可在选择的目录下生成所画的流程图对应的png图片 解决生成的图片乱码问题如果生成的图片上面字体乱码的话,则可以按照下面操作解决图片乱码问题 第一种: 直接打开xml文件,进入文件将乱码的字体改回来,再重新生成图片即可 第二种: 进入intellij的安装目录下的bin目录,找到以下两个文件 打开这两个文件,将以下配置复制粘贴到两个文件的末尾,保存.然后重启intellij,即可解决图片的中文乱码问题 -Dfile.encoding=UTF-8]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Eclipse整合svn步骤]]></title>
      <url>%2F2016%2F03%2F17%2FEclipse%E6%95%B4%E5%90%88svn%E6%AD%A5%E9%AA%A4%2F</url>
      <content type="text"><![CDATA[1) 点击eclipse的Help–&gt;Install New Software，点击add，并输入name：Subclipse 1.6.xlocation：http://subclipse.tigris.org/update_1.6.x 2) 点击next, 出现的选项全部选中 3) 等待自动下载 4) 自动下载完成以后出现 5) finish, 剩下的全部无脑安装]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[shrio学习]]></title>
      <url>%2F2016%2F03%2F17%2Fshrio%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%2F</url>
      <content type="text"><![CDATA[什么是shrioshrio是apache下的一个权限控制框架。登录到系统的用户有很多个，但是每个人可操作的功能和看到的页面可能会不一样，shrio就是用来解决这些的 shrio可以干什么使用shrio可以进行认证、鉴权、加密、会话管理 支持认证跨一个或多个数据源 执行授权，基于角色的细粒度的权限控制 增加的缓存支持 支持web和非web环境，可以在任何单点登录（sso）或集群分布式会话中使用。 shrio主要有四个组件 SecurityManager shrio通过它对外提供安全管理的各种服务 Authenticator 对登录到系统的用户进行核实，通常涉及用户名和密码 这个组件负责收集principals和credentials，并将它们提交给应用系统。如果提交的credentials跟应用系统提交的credentials吻合，就能继续访问，否则需要重新提交principals和credentials，或者直接终止访问 Authorizer 身份验证通过后,由这个组件对登录人员进行访问控制的筛查，比如“who can do what”，或者“who can do which actions”. shrio采用“基于Relam”的方法，即用户（又称Subject）、用户组、角色和permission的聚合体 Session Manager 这个组件保证了异构客户端的访问，配置简单，它是基于POJO/J2SE的，不跟任何的客户端或者协议绑定 Shrio运行原理 Application Code：应用程序代码，就是我们自己编写的项目代码。如果在程序中需要进行权限控制，需要调用Subject的api Subject:主体，代表了当前用户。所有的Subject都绑定到SecurityManager，与Subject的所有交互都会委托给SecurityManager，可以将Subject当作一个门面，真正执行者是SecurityManager SecurityManager：安全管理器，所有与安全有关的操作都会与SecurityManager交互，并且它管理所有的Subject Realm：域，shrio是通过Realm类来获取安全数据的，就是说SecurityManager要验证用户身份，那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法；也需要从Realm得到用户相应的角色/权限进行验证用户是否能进行操作，可以把Realm看成DataSource，即安全数据 shrio的几种权限控制方式 url级别权限控制 方法注解权限控制 代码级别权限控制 页面标签权限控制 一般项目都是使用的第一种方式 权限数据模型shrio的权限数据需要开发人员自己来提供，一般都是用的以下几张表 spring整合shrio点击http://shiro.apache.org/download.html下载shrio框架jar包 将shrio的jar包导入到项目中 在web.xml中配置一个过滤器代理对象，在项目启动时到spring工厂中加载一个和过滤器name相同的bean对象 &lt;!--配置shiro的过滤器,需要放在struts2前面--&gt; &lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 在spring配置文件中配置一个名称为shiroFilter的bean &lt;!--配置shiro的bean,使用当前工厂bean对象创建过滤器用于进行权限控制--&gt; &lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;!--下面三个都是默认值,不配的话就是下面这效果--&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;/login.jsp&quot;/&gt; &lt;property name=&quot;successUrl&quot; value=&quot;/index.jsp&quot;/&gt; &lt;!--权限不足提示页面--&gt; &lt;property name=&quot;unauthorizedUrl&quot; value=&quot;/unauthorized.jsp&quot;/&gt; &lt;!--基于url拦截 使用过滤器进行拦截--&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; &lt;!--*匹配任意字符 **匹配任意结构--&gt; /css/** = anon /js/** = anon /images/** = anon /validatecode.jsp* = anon /login.jsp = anon /user_login.action = anon /** = authc &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--配置安全管理器--&gt; &lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt; &lt;/bean&gt; 定义一个LoginController类，使用shrio进行验证 @Controller public class LoginController { @RequestMapping(&quot;/login&quot;) public void login(User user){ //获得Subject对象，用它来与SecurityManager交互 Subject subject = SecurityUtils.getSubject(); //获取用户名密码，并对密码进行加密（这里的密码可以加盐值） String username = user.getUsername(); String password = MD5Utils.md5(user.getPassword()); //创建认证令牌对象 AuthenticationToken token = new UsernamePasswordToken(username,password); try{ //调用安全管理器进行shrio认证登录,如果登录失败,会报异常 subject.login(token); System.out.println(&quot;登录成功&quot;); }catch(Exception e){ e.printStackTrace(); System.out.println(&quot;登录失败&quot;); } } } 自定义Relam类，进行认证和授权操作 public class LoginRealm extends AuthorizingRealm { @Resource IUserService UserService; @Resource FunctionDao functionDao; /** * 进行授权操作 * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) { //授权信息对象 SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); User user = (User) principalCollection.getPrimaryPrincipal(); String username = user.getUsername(); List&lt;Function&gt; functions = null; if (&quot;admin&quot;.equals(username)) { functions = functionDao.findAll(); } else { functions = functionDao.findFunctionById(user.getId()); } if (functions != null) { for (Function function : functions) { info.addStringPermission(function.getCode()); } } return info; } /** * 进行认证操作 * @param authenticationToken * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException { UsernamePasswordToken uptoken = (UsernamePasswordToken) authenticationToken; String username = uptoken.getUsername(); User user = userService.findUserByUsername(username); if (user == null) { return null; } //第一个参数,参数签名,可以为任何值,一般为认证对象,因为可以通过subject获取到 //第二个参数,需要比较的从数据库查出来的密码值 //第三个参数,当前realm类的类名 SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(user, user.getPassword(), this.getClass().getName()); return info; } } 在spring配置文件中，注册上面的Relam类，并注入给安全管理器 &lt;!--配置安全管理器--&gt; &lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt; &lt;!--在安全管理器中配置自定义的Realm类--&gt; &lt;property name=&quot;realm&quot; ref=&quot;LoginRealm&quot;/&gt; &lt;/bean&gt; &lt;!--realm类bean--&gt; &lt;bean id=&quot;LoginRealm&quot; class=&quot;com.yungou.realm.LoginRealm&quot;/&gt; 启动项目，shrio就已经应用到你的项目中啦]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用七牛云图床管理博客图片]]></title>
      <url>%2F2016%2F02%2F28%2F%E4%B8%83%E7%89%9B%E4%BA%91%E5%9B%BE%E5%BA%8A%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[前言 写文不加图片辅助感觉很难描述操作过程,如果使用github管理博客图片资源的话,又会影响文章加载速度.其他的诸如新浪博客相册,qq空间之类的可以上传图片的地方,在markdown文件中加入链接又比较麻烦,得一个个复制.后经朋友推荐,选择了七牛云图床管理博客图片资源.用起来确实蛮方便的. 创建七牛云帐号首先点击进入七牛云官网,在右上角选择注册. 信息填入完毕,点击下一步,选择个人,然后会要求你验证邮箱. 登录你的邮箱点击验证链接,会跳转到注册成功页面,并要求你进行实名验证 点击立即去实名验证 这里有两个选择,人工审核有点麻烦,我就选择了支付宝验证 输入信息之后会跳转到支付宝授权页面,输入支付宝的帐号和密码点击确定,就完成了认证操作 然后会跳转到七牛云登录页面,输入你的邮箱,和一开始填写注册信息时写的密码,就可以登录到七牛云了 登录之后上方会提示你绑定手机号,绑定一下就行了 上面全部完成之后,七牛云的帐号就算注册完毕了!接下来就可以创建对象存储空间了 创建七牛云对象存储空间点击右边菜单栏的对象存储 然后点击新建存储空间 这里的存储空间名称随便填一个就行,建议和github名一样,这样好记忆 使用命令行工具上传本地图片使用七牛云对象存储空间的内容管理页面上传本地资源,比较简单,就不介绍了.下面说一下windows下如何使用命令行工具上传本地图片 首先,下载七牛云提供的命令行工具,点击进入下载页面 然后往下拉,拉到下面这个地方,点击下载就可 下载完成解压,有以下几个文件,分别是各个系统的命令行工具,我是windows64位的,就选择了amd64,将其他的都删除了,并将文件名改为qshell,方便使用 使用qshell的qupload命令,需要提供一个配置文件,在qshell所在目录下新建一个文件,命名为config.json 配置文件中需要以下几个基本配置,详细的可配置参数请点击详细参数进行了解 { &quot;src_dir&quot; : &quot;&quot;, &quot;bucket&quot; : &quot;&quot;, &quot;access_key&quot; : &quot;&quot;, &quot;secret_key&quot; : &quot;&quot; } src_dir:即是你需要上传的图片所在的根目录,从盘符开始 bucket:你的对象存储空间名 access_key和secret_key是七牛云空间提供的密钥,下面将介绍如何获取 登录七牛云,点击个人面板,选择密钥管理 进入密钥页面,复制一下access_key和secret_key并粘贴到config.json中 如何上传本地图片我在d盘下新建了一个文件夹,名为images,在里面放了一个图片为a.jpg,和一个子文件夹,名为folder,在子文件夹里也放了一个图片为b.jpg 之后设置config.json中的src_dir参数为D:\images, 之后就在qshell文件所在目录按住shift然后右键,选择在此处打开命令行窗口,键入 qshell qupload 1 config.json 命令,就可以将本地资源上传到七牛云空间了.命令中的数字值代表启动几个线程上传图片,1代表1个线程,值1-2000之间可选,值并不是越高越好. 图片外链上传的图片外链为域名加上你上传的文件相对于src_dir参数的相对路径.我的src_dir参数为D:\images,则我两个图片相对于这个参数的相对路径分别为a.jpg和folder/b.jpg 我没有为存储空间绑定自己申请的域名,所以只可以用七牛云提供的测试域名,测试域名可以在你的存储空间页面空间概览中看到 我的测试域名是 oles6cv6e.bkt.clouddn.com 则我这两个图片外链分别为oles6cv6e.bkt.clouddn.com/a.jpg 和 oles6cv6e.bkt.clouddn.com/folder/b.jpg 在markdown文件中,使用如下格式,即可以为你的文章插入图片链接了 ![图片信息](图片外链) ![a.jpg](http://oles6cv6e.bkt.clouddn.com/a.jpg) ![b.jpg](http://oles6cv6e.bkt.clouddn.com/folder/b.jpg)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[markdown学习]]></title>
      <url>%2F2016%2F02%2F28%2Fmarkdown%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[强调 星号与下划线都可以,单是斜体,双是粗体,三个是粗斜体,符号可跨行,符号可加空格(单可以,双就不行了) **一个人来到田纳西** __毫无疑问__ *我做的馅饼 是全天下* _最好吃的_ 一个人来到田纳西毫无疑问我做的馅饼是全天下最好吃的 分隔线 三个或更多-_*，必须单独一行 引用 翻译成html就是blockquote标签，符号后的空格可不要 &gt;引用 引用 内层符号前的空格必须要(也不是必须要,就是必须换行) &gt;引用 &gt;&gt;引用中的引用 引用 引用中的引用 标题:Setext方式 =三个或更多(一个=也能形成大标题,小标题) 大标题 = 小标题 - 大标题=小标题- 标题:Atx方式 =#一级标题 ##二级标题 ###三级标题 ####四级标题 #####五级标题 ######六级标题 #一级标题 ##二级标题 ###三级标题 ####四级标题 #####五级标题 ######六级标题 无序列表 =符号之后的空格不能少，-+*效果一样，内容可超长,但不能混合使用，因混合是嵌套列表 - 无序列表 - 无序列表 - 无序列表 - 无序列表：我很长。我也很长！那比一比啊？比就比！我有这么长，你有我长吗？我有这么这么长！好吧，你赢了！ 无序列表 无序列表 无序列表 无序列表：我很长。我也很长！那比一比啊？比就比！我有这么长，你有我长吗？我有这么这么长！好吧，你赢了！ 符号之后的空格不能少，-+*效果一样，但不能混合使用，因混合是嵌套列表 + 无序列表 + 无序列表 + 无序列表 + 无序列表 发现了一个问题,就是在无序列表后面跟着写代码快得缩进两次,不然就被追加到最后一个列表项上去了, 不知道怎么回事 无序列表 无序列表 无序列表 无序列表 符号之后的空格不能少，-+*效果一样，但不能混合使用，因混合是嵌套列表 * 无序列表 * 无序列表 * 无序列表 * 无序列表 无序列表 无序列表 无序列表 无序列表 有序列表 =数字不能省略但可无序，点号之后的空格不能少 1. 有序列表 2. 有序列表 3. 有序列表 4. 有序列表 有序列表 有序列表 有序列表 有序列表 嵌套列表 =-+*可循环使用，但符号之后的空格不能少，符号之前的空格也不能少 - 嵌套列表 + 嵌套列表 + 嵌套列表 - 嵌套列表 * 嵌套列表 - 嵌套列表 只能嵌套两层吗?上面的效果如下,并没有三四层嵌套 嵌套列表 嵌套列表 嵌套列表 嵌套列表 嵌套列表 嵌套列表 文字超链 =Tooltips可省略 [windwest的博客](http://iwantthisname.github.io &quot;windwest的博客&quot;) windwest的博客 图片超链 =多个感叹号，Tooltips可省略，要设置大小只能借助HTML标记 ![GitHub Mark](http://github.global.ssl.fastly.net/images/modules/logos_page/GitHub-Mark.png &quot;GitHub Mark&quot;) 索引超链：Reference方式 =索引，1 2可以是任意字符 [windwest的博客][1] ![GitHub Octocat][2] [1]:http://IWantThisName.github.io [2]:http://github.global.ssl.fastly.net/images/modules/logos_page/Octocat.png windwest的博客 自动链接 =尖括号 &lt;http://www.baidu.com&gt; &lt;201800978@qq.com&gt; http://www.baidu.com &#50;&#x30;&#49;&#56;&#48;&#48;&#x39;&#55;&#x38;&#64;&#x71;&#x71;&#x2e;&#99;&#111;&#x6d; 代码:行内代码 =在第一行后指定编程语言，也可以不指定 val s = &quot;hello Markdown&quot; println( s )]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[博客应用next主题]]></title>
      <url>%2F2016%2F02%2F27%2F%E5%8D%9A%E5%AE%A2%E5%BA%94%E7%94%A8next%20%E4%B8%BB%E9%A2%98%2F</url>
      <content type="text"><![CDATA[下载next主题并应用到hexo博客上 下载next主题点击这里按照下图进行下载 下载完成后进行解压将解压后的文件夹名字重命名为next,放到blog目录下的theme文件夹下 修改blog目录下的_config.yml站点配置文件 在blog目录下按住shift+右键,打开命令行窗口 在命令行里键入以下命令 D:\nodejs\blog&gt; hexo g D:\nodejs\blog&gt; hexo d 然后重新键入你的博客页面,就可以看到页面已经更换了 next主题的一些优化以下的配置文件修改都是针对next主题下的_config.yml文件,修改后重新hexo g,hexo d即可以看到修改效果 主题风格的选择默认有三种风格可以选择,我选择的是Mist 菜单页面配置我选择显示了主页,关于页,分类页,标签页和归档页,如下所示 头像设置就是设置这里的头像将要设置的图像重名为avatar.gif覆盖在themes/next/source/images下avatar.gif文件就可以设置自己想要的头像了需要注意的是,只能覆盖avatar.gif,不然会报错= =在themes/next/_config.yml文件中有下面这个配置但是设置了自己定义的图片名还是会报错 设置文章的代码主题有5中代码风格可以选择,我选择的是normal 引入第三方服务以下的配置文件修改都是针对next主题下的_config.yml文件,修改后重新hexo g,hexo d即可以看到修改效果 加入评论功能点击这里注册多说评论服务登录多说后,点击我要安装然后填写相应信息,主要的就是下方画红圈处记住你填写的多说域名,然后去修改配置文件修改后的效果为,每篇博客后都有 加入分享功能分享功能也是使用的多说按照下面修改配置文件,将duoshuo_share设置为true修改后的效果为,每篇博客后都有 加入站点搜索功能本站点使用的是Local Search。加入站点内容搜索功能步骤如下：安装hexo-generator-searchdb $ npm install hexo-generator-searchdb --save 注意：安装时应在站点根目录下，即blog目录下不过我安装失败了 = = (貌似是因为我以前安装过了)如果安装成功,就修改站点的配置文件(blog目录下的,不是next主题下的),添加如下字段然后就可以生效了,效果如下]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[git+github page+hexo搭建个人博客]]></title>
      <url>%2F2016%2F02%2F27%2Fgit%2Bgithub%20page%2Bhexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
      <content type="text"><![CDATA[前言 一直想自己搭建一个博客记录学习中遇到的问题,以便以后查阅.在百度了之后,决定采取这最简单而且免费的方式.经过了几个小时的摸索,终于可以在浏览器上访问到自己的博客,还是有点成就感的,所以自己的第一篇博客就决定来记录一下博客的搭建过程. 博客搭建所需环境 windows7 64位 node-v6.95-x64.msi Git-2.11.1-64-bit.exe 2和3直接百度下载,下载完之后点击安装,一路下一步就行,唯一需要注意的就是node的安装目录需要知道在哪里,之后会用到,最好将目录更改成自己好记忆的. 在都安装完之后需要配置一下node的环境变量,在windows桌面右键计算机图标–&gt;点击属性–&gt;点击高级系统设置–&gt;点击环境变量,在下面的系统变量中找到path变量,追加一下node的安装目录. 安装hexo 在node安装目录下,按住shift后点击右键,选择在此处打开命令行窗口 输入 npm install -g hexo 命令 等待稍长一段时间,hexo就安装成功了 开始搭建博客 接着上一步,输入 mkdir blog &amp;&amp; cd blog 命令,创建blog文件夹并进入,这个名字可以是任意的,这个文件夹所在目录就是今后的博客目录 输入 hexo init 命令,初始化hexo博客框架的一些文件 输入 npm install 命令,安装hexo博客框架所需的依赖 以上博客已经搭建成功了,不过只是本地的,此时输入 hexo g 命令即可生成静态页面 执行hexo s 命令,然后在浏览器键入 http://localhost:4000 即可看到博客页面 将本地博客部署到github上 首先得在github上创建一个帐号,点击进入github 点击右上角+号选择new repositry创建仓库,仓库名固定格式为github名.github.io,我的github名是iwantthisname,所以在这里我就输入了iwantthisname.github.io 创建成功之后点击你刚刚创建好的仓库,在右上点击setting.然后找到choose theme,选择一个主题确定(这里主题随便选择一个就行,后面都可以换),这样你的github page就创建成功了,可以试试在浏览器上输入你的github名.github.io看看能不能访问到 再回到仓库主页code那一标签页,点击clone or download后会有一个下拉框,复制框里面的仓库地址 进入node的安装目录,点击刚才创建好的blog文件夹(就是上面说明的博客目录),打开_config.yml文件,在文件任意位置加入以下配置 deploy: type: git repository: (直接粘贴你刚才复制的仓库地址) branch: master 回到你的cmd窗口,执行npm install hexo-deployer-git –save 命令,这命令是用来解决发布项目问题的 执行hexo g 命令生成静态页面 执行hexo d 命令将静态页面推送到github上 在浏览器输入 你的github名.github.io,应该就可以看到你的博客页面了 编写发布博客 首先介绍一下博客目录下一些重要的目录 public:和远程仓库的内容同步 source:这个文件夹下的_post的文件可以用来生成静态资源并发布到远程仓库上 themes:博客的主题文件存放目录 进入source目录下的_post文件夹,这个文件夹下放的一般是markdown文件,所以得先下载markdown编辑器.百度一下即可下载,安装也是一路下一步就行,没什么注意的地方. 编辑器下载完成,即可在这个文件夹下创建一个markdown文件,markdown文件编写语法也比较简单,可以百度个博客稍微学习一下,在文件中编写自己的博客内容 进入命令行中执行 hexo g 命令生成静态资源,在执行hexo d命令进行发布 在浏览器中键入 你的github名.github.io 即可以看到你刚发布的博客啦 使用自己的域名绑定github page如果你觉得github名.github.io这个地址不好记,想用自己申请的域名访问自己的博客,就可以按照下面的步骤,将自己的域名绑定到github page上啦 域名添加github page解析 首先申请个域名,我是在阿里云上申请的,点击进入阿里云 申请好之后,点击控制台,在左边菜单栏进入域名管理 在你申请的域名那一栏 点击解析,进入解析设置页面 点击添加解析,这里需要添加三个 记录类型 主机记录 记录值 TTL A @ 192.30.252.153 10分钟(600秒) A @ 192.30.252.154 10分钟(600秒) CNAME www github名.github.io 10分钟(600秒) github page添加域名解析 回到你的github主页,进入你的github page仓库,进入Setting页面,在Customer domain栏里填入你的域名,点击save保存 静待片刻,在浏览器输入你的域名,即可看到你的博客页面了]]></content>
    </entry>

    
  
  
</search>
